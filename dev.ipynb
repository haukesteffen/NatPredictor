{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **NATIONALITY PREDICTION**\n",
    "\n",
    "The goal of this notebook is to create a model that can predict nationalities from name strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, IterableDataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from unidecode import unidecode\n",
    "import country_converter as coco\n",
    "import yaml\n",
    "\n",
    "\n",
    "device: str = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **IMPORT DATA**\n",
    "\n",
    "- Import data from selected (todo: all) CSV files\n",
    "- Use n (todo: all) samples from imported dataframe\n",
    "- Concatenate dataframes, generate 'name' and 'nationality' columns\n",
    "- Create vocabularies for inputs and outputs:\n",
    "- Input vocabulary links characters to index integers and vice versa\n",
    "- Output vocabulary links nationalities to index integers and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXIMUM_NAME_LENGTH: int  = 50 # maximum number of characters\n",
    "BATCH_SIZE: int = 256 # number of training examples per batch\n",
    "N_EVAL: int = 100 # evaluate loss every n batches\n",
    "N_TRAINING_STEPS: int = 301 # number of trainings steps \n",
    "\n",
    "# read country codes\n",
    "with open('./data/.country_codes', 'r') as f:\n",
    "    COUNTRY_CODES: list = f.read().splitlines()\n",
    "\n",
    "#read vocabulary\n",
    "with open('./data/.vocabulary', 'r') as f:\n",
    "    VOCABULARY: str = f.read()\n",
    "\n",
    "# generate country code mappings\n",
    "target_class: str = 'UNregion' # see country_converter documentation on PyPI for available classes\n",
    "COUNTRY_MAPPING: dict = {cc: coco.convert(names=cc, to=target_class) for cc in COUNTRY_CODES} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameNationalityDataStream(IterableDataset):\n",
    "    \"\"\"\n",
    "    A simple IterableDataset that streams data from a single CSV file containing name and nationality in chunks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        Path to the CSV file.\n",
    "    chunksize : int\n",
    "        Number of rows to read per chunk.\n",
    "    maximum_name_length : int\n",
    "        Number of characters after which names in input get truncated\n",
    "    vocabulary : str\n",
    "        String of all unique characters in vocabulary\n",
    "    country_codes : list\n",
    "        List of all unique country codes in dataset\n",
    "    country_mapping : dict\n",
    "        Dictionary of alpha2 to target category mapping (e.g. UN region)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_file: str,\n",
    "        chunksize: int,\n",
    "        maximum_name_length: int,\n",
    "        vocabulary: str,\n",
    "        country_codes: list,\n",
    "        country_mapping: dict\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.data_file: str = data_file\n",
    "        self.chunksize: int = chunksize\n",
    "        self.maximum_name_length: int = maximum_name_length\n",
    "        self.vocabulary: str = vocabulary\n",
    "        self.country_codes: list = country_codes\n",
    "        self.country_mapping: dict = country_mapping\n",
    "        self.padding_index: int = 0\n",
    "\n",
    "        # generate input mappings (character to index and vice versa)\n",
    "        (self.character_to_index,\n",
    "         self.index_to_character,\n",
    "         self.vocabulary_length) = self._generate_name_mapping(\n",
    "            self.vocabulary\n",
    "        )\n",
    "\n",
    "        # generate output mappings (alpha2 to index as well as class (e.g. UN region) to index and vice versa)\n",
    "        (self.class_to_index,\n",
    "         self.index_to_class,\n",
    "         self.alpha2_to_index,\n",
    "         self.number_of_classes) = self._generate_country_mapping(\n",
    "            self.country_codes,\n",
    "            self.country_mapping\n",
    "        )\n",
    "\n",
    "    def _generate_name_mapping(self, vocabulary):\n",
    "        \"\"\"\n",
    "        Each character of the vocabulary is assigned an integer index, starting at 1 so that 0 can be \n",
    "        used as a padding index. The vocabulary is a list of unique characters generated from the dataset.\n",
    "        This method also prints out the vocabulary and vocabulary length.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        vocabulary : str\n",
    "            A string of unique characters generated from the input dataset.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple of (dict, dict, int):\n",
    "            ctoi : dict\n",
    "                Mapping from character to integer index.\n",
    "            itoc : dict\n",
    "                Mapping from integer index back to character.\n",
    "            vocabulary_length : int\n",
    "                The number of unique characters in vocabulary.\n",
    "        \"\"\"\n",
    "        vocabulary_length = len(vocabulary)\n",
    "        print(f\"Vocabulary of length {vocabulary_length}:\\n{vocabulary}\")\n",
    "        ctoi = {c:i for i, c in enumerate(vocabulary, 1)} # start enumeration at 1 because 0 is padding index\n",
    "        itoc = {i:c for i, c in enumerate(vocabulary, 1)}\n",
    "        return ctoi, itoc, vocabulary_length\n",
    "\n",
    "    def _generate_country_mapping(self, country_codes, country_mapping):\n",
    "        \"\"\"\n",
    "        Generate mappings between target classes and their indices based on country codes.\n",
    "\n",
    "        This method creates three mappings:\n",
    "        - A mapping from each target class (e.g., UN region) to a unique index (starting at 1,\n",
    "            since index 0 is reserved for padding).\n",
    "        - The inverse mapping from these indices back to the target classes.\n",
    "        - A mapping from each country code in the provided list to the corresponding class index,\n",
    "            as determined by the country_mapping dictionary.\n",
    "\n",
    "        Additionally, it calculates the total number of distinct target classes and prints this number\n",
    "        along with a list of the target classes.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        country_codes : list\n",
    "            A list of all country codes present in the dataset.\n",
    "        country_mapping : dict\n",
    "            A dictionary mapping each country code to its target class.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple of (dict, dict, dict, int):\n",
    "            class_to_index : dict\n",
    "                Mapping from target class to its unique index.\n",
    "            index_to_class : dict\n",
    "                Mapping from index to target class.\n",
    "            alpha2_to_index : dict\n",
    "                Mapping from country codes to their corresponding class indices.\n",
    "            number_of_classes : int\n",
    "                The total number of distinct target classes.\n",
    "        \"\"\"\n",
    "        output_classes = set(country_mapping.values())\n",
    "        number_of_classes = len(output_classes)\n",
    "        print(f'Number of target classes: {number_of_classes}:\\n{\", \".join(output_classes)}')\n",
    "        class_to_index = {c:i for i, c in enumerate(output_classes, 1)} # start enumeration at 1 because 0 is padding index\n",
    "        index_to_class = {i:c for c, i in class_to_index.items()}\n",
    "        alpha2_to_index = {country: class_to_index[country_mapping[country]] for country in country_codes}\n",
    "        return class_to_index, index_to_class, alpha2_to_index, number_of_classes \n",
    "    \n",
    "    def _encode_name(self, seq):\n",
    "        \"\"\"\n",
    "        Encodes a single string or a list of strings into integer indices based on `self.character_to_index`,\n",
    "        replacing unmapped characters with `self.padding_index`. Each encoded sequence is then padded\n",
    "        to `self.maximum_name_length`, and the original (unpadded) lengths are recorded.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        seq : str or list of str\n",
    "            The input string(s) to be converted.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple of (torch.Tensor, torch.Tensor):\n",
    "            If input is a single string:\n",
    "                padded_tensor : torch.Tensor of shape (self.maximum_name_length,)\n",
    "                sequence_length : torch.Tensor (scalar) indicating the original length\n",
    "            If input is a list of strings:\n",
    "                padded_tensors : torch.Tensor of shape (batch_size, self.maximum_name_length)\n",
    "                sequence_lengths : torch.Tensor of shape (batch_size,) indicating the original lengths\n",
    "        \"\"\"\n",
    "        assert isinstance(seq, (str, list)), \"Input must be string or list of strings\"\n",
    "        \n",
    "        if isinstance(seq, str):\n",
    "            # Process single string without wrapping it in a list.\n",
    "            encoded = [self.character_to_index.get(char, self.padding_index) for char in seq]\n",
    "            seq_len = len(encoded)\n",
    "            padded_tensor = torch.full((self.maximum_name_length,), self.padding_index, dtype=torch.int32)\n",
    "            max_len = min(seq_len, self.maximum_name_length)\n",
    "            padded_tensor[:max_len] = torch.tensor(encoded[:max_len], dtype=torch.int32)\n",
    "            return padded_tensor, torch.tensor(max_len, dtype=torch.int32)\n",
    "        \n",
    "        else:  # seq is a list of strings\n",
    "            encoded_input = []\n",
    "            for s in seq:\n",
    "                assert isinstance(s, str), \"Each element in the list must be a string\"\n",
    "                encoded_input.append([self.character_to_index.get(char, self.padding_index) for char in s])\n",
    "            sequence_lengths = torch.tensor(\n",
    "                [min(len(encoding), self.maximum_name_length) for encoding in encoded_input],\n",
    "                dtype=torch.int32\n",
    "            )\n",
    "            batch_size = len(encoded_input)\n",
    "            padded_tensors = torch.full(\n",
    "                (batch_size, self.maximum_name_length),\n",
    "                self.padding_index,\n",
    "                dtype=torch.int32\n",
    "            )\n",
    "            for i, encoding in enumerate(encoded_input):\n",
    "                seq_len = len(encoding)\n",
    "                max_len = min(seq_len, self.maximum_name_length)\n",
    "                padded_tensors[i, :max_len] = torch.tensor(encoding[:max_len], dtype=torch.int32)\n",
    "            \n",
    "        return padded_tensors, sequence_lengths\n",
    "\n",
    "    def _decode_name(self, seq_tensor):\n",
    "        \"\"\"\n",
    "        Decodes a 1D or 2D tensor of integer indices into characters using the `self.index_to_character` mapping.\n",
    "        \n",
    "        - If `seq_tensor` is 1D (shape: [N]), it decodes a single sequence of characters.\n",
    "        - If `seq_tensor` is 2D (shape: [B, N]), it decodes multiple sequences (one per row).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        seq_tensor : torch.Tensor\n",
    "            A 1D or 2D tensor of integer indices.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list of str:\n",
    "            If the input is 1D, returns a single-element list with the decoded name string.\n",
    "            If the input is 2D, returns a list of decoded names, one per row.\n",
    "        \"\"\"\n",
    "        if not isinstance(seq_tensor, torch.Tensor):\n",
    "            raise TypeError(\"seq_tensor must be a torch.Tensor of integer indices.\")\n",
    "        if seq_tensor.dim() == 1:\n",
    "            return [''.join([self.index_to_character.get(int(idx), '') for idx in seq_tensor])]\n",
    "        elif seq_tensor.dim() == 2:\n",
    "            decoded_sequences = []\n",
    "            for row in seq_tensor:\n",
    "                decoded_sequences.append(''.join([self.index_to_character.get(int(idx), '') for idx in row]))\n",
    "            return decoded_sequences\n",
    "        else:\n",
    "            raise ValueError(\"seq_tensor must be a 1D or 2D tensor of integer indices.\")\n",
    "\n",
    "    def _encode_country(self, country_input):\n",
    "        \"\"\"\n",
    "        Encode a country code or a list of country codes into one-hot vectors.\n",
    "\n",
    "        This method maps the input country code(s) to their corresponding indices using\n",
    "        `self.alpha2_to_index`. If a country code is not found in the mapping, the padding\n",
    "        index (`self.padding_index`) is used. The resulting indices are then converted into\n",
    "        one-hot encoded tensors with a dimensionality of `self.number_of_classes + 1` (to account\n",
    "        for the padding index).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        country_input : str or list of str\n",
    "            A single country code or a list of country codes.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        encoded_tensors : torch.Tensor\n",
    "            A tensor containing the one-hot encoded representation(s) of the input.\n",
    "        \"\"\"\n",
    "        assert isinstance(country_input, (str, list)), 'Input must be string or list of strings'\n",
    "        if isinstance(country_input, str):\n",
    "            encoded_output = self.alpha2_to_index.get(country_input, self.padding_index)\n",
    "        elif isinstance(country_input, list):\n",
    "            encoded_output = []\n",
    "            for c in country_input:\n",
    "                assert isinstance(c, str), 'Input must be string or list of strings'\n",
    "                encoded_output.append(self.alpha2_to_index.get(c, self.padding_index))\n",
    "        index_tensors = torch.tensor(encoded_output, dtype=torch.int64)\n",
    "        encoded_tensors = F.one_hot(index_tensors, num_classes=self.number_of_classes+1).to(torch.float32)\n",
    "        return encoded_tensors      \n",
    "\n",
    "    def _decode_country(self, country_code_tensor):\n",
    "        \"\"\"\n",
    "        Decodes a 1D or 2D one-hot-encoded tensor into its corresponding country code strings.\n",
    "\n",
    "        For a 1D tensor (shape: [num_classes]), it finds the index of the maximum value \n",
    "        (the argmax) and returns a list containing the corresponding country code.\n",
    "\n",
    "        For a 2D tensor (shape: [batch_size, num_classes]), it applies the same argmax \n",
    "        operation along each row, returning a list of country codes for the entire batch.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        country_code_tensor : torch.Tensor\n",
    "            A 1D or 2D tensor representing one-hot-encoded country codes.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list of str\n",
    "            - If the input is 1D, returns a single-element list with the decoded country code.\n",
    "            - If the input is 2D, returns a list of decoded country codes, one per row.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        TypeError\n",
    "            If `country_code_tensor` is not a torch.Tensor.\n",
    "        ValueError\n",
    "            If `country_code_tensor` is neither 1D nor 2D.\n",
    "        \"\"\"\n",
    "        if not isinstance(country_code_tensor, torch.Tensor):\n",
    "            raise TypeError(\"country_code_tensor must be a torch.Tensor of integer indices.\")\n",
    "        if country_code_tensor.dim() == 1:\n",
    "            return [self.index_to_class.get(torch.argmax(country_code_tensor).item(), 'Unknown')]\n",
    "        elif country_code_tensor.dim() == 2:\n",
    "            decoded_output = []\n",
    "            for encoding in country_code_tensor:\n",
    "                index = torch.argmax(encoding).item()\n",
    "                decoded_output.append(self.index_to_class.get(index, 'Unknown'))\n",
    "            return decoded_output\n",
    "        else:\n",
    "            raise ValueError(\"country_code_tensor must be a 1D or 2D tensor of integer indices.\")\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Stream rows from the CSV in chunks of `chunksize`, yielding them one by one.\n",
    "\n",
    "        Yields\n",
    "        ------\n",
    "        Tuple of torch.Tensor, torch.Tensor, torch.Tensor\n",
    "        \"\"\"\n",
    "        for chunk in pd.read_csv(self.data_file, chunksize=self.chunksize):\n",
    "            for _, row in chunk.iterrows():\n",
    "                # encode training inputs as padded index tensors\n",
    "                X, sequence_lengths = self._encode_name(\n",
    "                    row['name']\n",
    "                )\n",
    "                # scale output values and convert to torch.Tensor\n",
    "                y = self._encode_country(\n",
    "                    row['alpha2']\n",
    "                )\n",
    "                yield X, y, sequence_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary of length 11658:\n",
      " !#$%&()*-./:;<=ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}¡¢£¤¥¦§¨©ª«¬®¯°±´µ¶·¸º»¼½¾¿ÀÁÂÃÄÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖ×ØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõöøùúûüýþÿĀāĂăĄąĆćĈĉĊċČčĎďĐđĒēĔĕĖėĘęĚěĜĝĞğĠġĢģĤĥĦħĨĩĪīĬĭĮįİıĲĳĴĵĶķĸĹĺĻļĽľĿŀŁłŃńŅņŇňŉŊŋŌōŎŏŐőŒœŔŕŖŗŘřŚśŜŝŞşŠšŢţŤťŦŧŨũŪūŬŭŮůŰűŲųŴŵŶŷŸŹźŻżŽžſƀƁƂƃƄƅƆƇƈƉƊƋƌƍƎƏƐƑƒƓƔƕƖƗƘƙƚƛƜƝƞƟƠơƢƣƤƥƦƧƨƩƪƫƬƭƮƯưƱƲƳƴƵƶƸƹƺƻƼƽƾƿǀǂǅǆǍǎǏǐǑǒǓǔǕǖǗǘǙǚǛǜǝǞǟǠǡǢǣǤǥǦǧǨǩǪǫǬǭǮǯǰǳǴǵǶǷǸǹǺǻǼǽǾǿȀȁȂȃȄȅȆȇȈȉȊȋȌȍȎȏȐȑȒȓȔȕȖȗȘșȚțȜȝȞȟȠȡȢȣȤȥȦȧȨȩȪȫȬȭȮȯȰȱȲȳȴȵȶȷȸȹȺȻȼȽȾȿɀɃɄɅɆɇɈɉɊɋɌɍɎɏɐɑɒɓɔɕɖɗɘəɚɛɜɝɞɟɠɡɢɣɤɥɦɧɨɩɪɫɭɮɯɱɲɳɴɵɶɷɸɹɺɽɾɿʀʁʂʃʄʅʆʇʈʉʊʋʌʍʎʏʐʑʒʓʘʙʚʛʜʝʞʟʠʡʢʥʩʬʭʮʯʰʳʹʼʾˆˇˎː˘˚˛˜˟ˡˢˣ˫̴̵̶̷̸̡̢̧̨̛̖̗̘̙̜̝̞̟̠̣̤̥̦̩̪̫̬̭̮̯̰̱̲̳̹̺̻̼͇͈͉͍͎̀́̂̃̄̅̆̇̈̉̊̋̌̍̎̏̐̑̒̓̔̽̾̿͂͆͊͋͌̕̚ͅ͏͓͔͕͖͙͚͐͑͒͗͛ͣͤͥͦͧͨͩͪͫͬͭͮͯ͘͜͟͢͝͞͠͡ͶͷͺͼͽͿΆΈΉΊΌΎΏΐΑΒΓΔΕΖΗΘΙΚΛΜΝΞΟΠΡΣΤΥΦΧΨΩΪΫάέήίΰαβγδεζηθικλμνξοπρςστυφχψωϊϋόύώϏϐϑϒϓϔϕϖϗϘϙϚϛϜϝϢϥϧϨϩϪϫϭϯϲϳϵϺϻϾϿЀЁЂЃЄЅІЇЈЉЊЋЌЍЎЏАБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдежзийклмнопрстуфхцчшщъыьэюяѐёђѓєѕіїјљњћќѝўџѠѡѢѣѥѦѧѨѩѪѫѬѭѮѯѰѱѲѳѴѵѶѷѺѻѼѽѾѿҁ҃҄҅҆҇҈҉ҊҋҍҎҏҐґҒғҔҕҖҗҘҙҚқҜҝҞҟҠҡҢңҤҥҦҧҨҩҪҫҬҭҮүҰұҲҳҴҵҶҷҸҹҺһҼҽҾҿӀӁӂӃӄӆӇӈӉӊӍӎӏӐӑӒӓӕӗӘәӚӛӝӟӠӡӢӣӤӥӦӧӨөӪӫӭӮӯӱӲӳӵӶӷӻӼӽӿԀԁԂԃԄԅԆԇԊԋԌԍԎԏԑԔԕԖԗԚԛԱԲԳԴԵԶԷԸԹԺԻԼԽԾԿՀՁՂՃՄՅՆՇՈՉՊՋՌՍՎՏՐՑՒՓՔՕՖՙ՚՜՞աբգդեզէըթժիլխծկհձղճմյնշոչպջռսվտրցւփքօֆև։֊ְֱֲֳִֵֶַָֹֺֻּ֮֔֙֟֫־ֿׁׂ׆ׇאבגדהוזחטיךכלםמןנסעףפץצקרשתװױײ׳״،؍؏ؘؙؚؐؑؒؓؔؕؖ؛؞؟ؠءآأؤإئابةتثجحخدذرزسشصضطظعغػؼؽؾؿـفقكلمنهوىيًٌٍَُِّْٕٖٜٓٔٗ٘ٙٚٛٝٞ٪٫٬٭ٮٯٰٱٲٳٴٵٶٷٸٹٺٻټٽپٿڀځڂڃڄڅچڇڈډڊڋڌڍڎڏڐڑڒړڔڕږڗژڙښڛڜڝڞڟڠڡڢڣڤڥڦڧڨکڪګڬڭڮگڰڱڲڳڴڵڶڷڸڹںڻڼڽھڿۀہۂۃۄۅۆۇۈۉۊۋیۍێۏېۑےۓ۔ەۖۗۘۙۚۛۜ۞ۣ۟۠ۡۢۤۥۦ۪ۭۧۨ۫۬ۮۯۺۻۼ۽ۿ܀܃ܐܑܒܓܔܕܖܗܘܙܚܛܜܝܞܟܠܡܢܣܤܥܦܧܨܩܪܫܬܭܸܹܼ݂݄݆݈ܰܲܳܵܶܺܽܿ݁݃݅݇݉݊ݐݑݒݓݔݕݖݗݘݙݚݛݜݝݞݟݠݡݢݣݤݥݦݧݨݩݪݫݬݭݯݰݱݲݳݴݶݷݸݹݺݻݼݽݾݿހށނރބޅކއވމފދތލގޏސޑޒޓޔޕޖޗޘޙޚޛޜޝޞޟޠޢޣޤަާިީުޫެޭޮޯްޱߊߋߌߍߎߏߐߒߓߔߕߖߗߘߙߚߛߜߝߞߟߠߡߢߣߤߥߦ߲߫߬߭߮߰߱ߴߺࠃࡀࡃࡅࡉࡋࡌࡎࣰࣲࣩࣥࣨ࣪࣫ࣳࣵࣷࣸँंःअआइईउऊऋऌऍऎएऐऑऒओऔकखगघङचछजझञटठडढणतथदधनऩपफबभमयरऱलळऴवशषसहऻ़ऽािीुूृॄॅॆेैॉॊोौ्ॏॐ॒॑॓॔ॕॖॗख़ड़ढ़ॠॡॢॣ।॥॰ॱॲॶॼঁংঃঅআইঈউঊঋঌএঐওঔকখগঘঙচছজঝঞটঠডঢণতথদধনপফবভমযরলশষসহ়ঽািীুূৃৄেৈোৌ্ৎৗড়য়ৠৡৢৣৰৱਁਂਃਅਆਇਈਉਊਏਐਓਔਕਖਗਘਙਚਛਜਝਞਟਠਡਢਣਤਥਦਧਨਪਫਬਭਮਯਰਲਵਸ਼ਸਹ਼ਾਿੀੁੂੇੈੋੌ੍ੑਖ਼ਜ਼ੜੰੱੲੳੴੵઁંઃઅઆઇઈઉઊઋઌઍએઐઑઓઔકખગઘઙચછજઝઞટઠડઢણતથદધનપફબભમયરલળવશષસહ઼ઽાિીુૂૃૄૅેૈૉોૌ્ૐૠૣଁଂଃଅଆଇଈଉଊଋଏଐଓଔକଖଗଘଙଚଛଜଝଞଟଠଡଢଣତଥଦଧନପଫବଭମଯରଲଳଵଶଷସହ଼ଽାିୀୁୂୃୄେୈୋୌ୍ୟୱஂஃஅஆஇஈஉஊஎஏஐஒஓஔகஙசஜஞடணதநனபமயரறலளழவஶஷஸஹாிீுூெேைொோௌ்ௐௗఁంఃఅఆఇఈఉఊఋఎఏఐఒఓఔకఖగఘఙచఛజఝఞటఠడఢణతథదధనపఫబభమయరఱలళవశషసహఽాిీుూృౄెేైొోౌ్ౖౙౠౢಂಃಅಆಇಈಉಊಋಌಎಏಐಒಓಔಕಖಗಘಙಚಛಜಝಞಟಠಡಢಣತಥದಧನಪಫಬಭಮಯರಱಲಳವಶಷಸಹ಼ಾಿೀುೂೃೆೇೈೊೋೌ್ೕೖೠೡംഃഅആഇഈഉഊഋഎഏഐഒഓഔകഖഗഘങചഛജഝഞടഠഡഢണതഥദധനപഫബഭമയരറലളഴവശഷസഹഺഽാിീുൂൃൄെേൈൊോൌ്ൗൺൻർൽൾංඃඅආඇඈඉඊඋඌඍඏඐඑඒඓඔඕඖකඛගඝඞඟචඡජඣඤඥඦටඨඩඪණඬතථදධනඳපඵබභමඹයරලවශෂසහළෆ්ාැෑිීුූෘෙේෛොෝෞෟ෴กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลฦวศษสหฬอฮฯะัาำิีึืฺุูเแโใไๅๆ็่้๊๋์ํ๎๏๛ກຂຄງຈຊຍດຕຖທນບປຜຝພຟມຢຣລວສຫອຮະັາຳິີຶືຸູົຼຽເແໂໃໄໆ່້໊໋໌ໍໜໝༀ༆༈་༌།༎༏༑༔༵༼༽ཀཁགངཅཆཇཉཊཋཌཎཏཐདནཔཕབམཙཚཛཝཞཟའཡརལཤཥསཧཨཪཬཱིེཻོཽུཾཿ྄ྀྂྃྈྋྐྒྔྕྗྙྚྟྡྣྤྦྨྩྫྭྰྱྲླྵྶྷ࿆ကခဂဃငစဆဇဈဉညဋဌဍဎဏတထဒဓနပဖဗဘမယရလဝသဟဠအဢဣဤဥဦဧဨဩဪါာိီုူေဲဳဴဵံ့း္်ျြွှဿ၊။၌၍၎၏ၐၑၒၓၔၕၗၚၛၜၝၞၠၡၢၣၤၥၦၧၨၪၫၬၭၰၱၲၳၵၶၷၸၹၺၻၼၽၾၿႀႁႂႃႄႅႆႇႈႉႊႋႌႍႎႏႚႜႝႠႢႣႨႩႫႬႮႰႵႶႷႿჁაბგდევზთიკლმნოპჟრსტუფქღყშჩცძწჭხჯჰჱჲჳჴჵჶჷჹჺᄀᄅᄽᅮᆞሀሁሂሃሄህሆሇለሉሊላሌልሎሏሐሑሒሓሔሕሖሗመሙሚማሜምሞሟሠሡሢሣሤሥሦሧረሩሪራሬርሮሯሰሱሲሳሴስሶሷሸሹሺሻሼሽሾሿቀቁቂቃቄቅቆቇቈቋቌቐቑቒቓቕቖቚቛቜበቡቢባቤብቦቧቨቩቪቫቬቭቮቯተቱቲታቴትቶቷቸቹቺቻቼችቾቿኀኁኂኃኄኅኆኈኊኋኌኍነኑኒናኔንኖኗኘኙኚኛኜኝኞኟአኡኢኣኤእኦኧከኩኪካኬክኮኯኰኲኳኴኵኸኹኺኻኼኽኾዂዃዄወዉዊዋዌውዎዏዐዑዒዓዔዕዖዘዙዚዛዜዝዞዟዠዡዢዣዤዥዦየዩዪያዬይዮዯደዱዲዳዴድዶዷዸዹዺዻዼዽዾጀጁጂጃጄጅጆጇገጉጊጋጌግጎጏጐጒጓጔጕጘጙጚጛጝጟጠጡጢጣጤጥጦጧጨጩጪጫጬጭጮጯጰጱጲጳጴጵጶጷጸጹጺጻጼጽጾፀፁፂፃፄፅፆፇፈፉፊፋፌፍፎፏፐፑፒፓፔፕፖፗፙፚ፝፟፠፡።፣፤፦ᎀᎁᎂᎃᎄᎅᎆᎇᎋᎠᎡᎢᎣᎤᎥᎦᎧᎨᎩᎪᎫᎬᎭᎮᎯᎰᎱᎲᎳᎴᎵᎶᎷᎸᎹᎻᎽᎾᎿᏀᏁᏂᏃᏄᏅᏆᏇᏉᏊᏋᏌᏍᏎᏐᏑᏒᏓᏔᏕᏖᏗᏘᏙᏚᏛᏜᏝᏞᏟᏠᏡᏢᏣᏤᏥᏦᏧᏨᏩᏪᏫᏬᏮᏯᏰᏱᏲᏳᏴᏸᏹᏺᏻᏼᐁᐃᐄᐅᐊᐎᐏᐑᐒᐘᐜᐝᐟᐢᐤᐦᐧᐨᐪᐯᐳᐴᐶᐸᐺᐻᑂᑆᑉᑊᑋᑌᑎᑐᑑᑕᑖᑘᑛᑜᑢᑣᑤᑦᑧᑨᑪᑫᑬᑭᑮᑯᑲᑳᑶᑷᑸᑹᑾᑿᒀᒁᒂᒃᒄᒆᒉᒋᒌᒍᒎᒏᒐᒑᒘᒙᒚᒛᒜᒝᒣᒤᒥᒦᒧᒪᒫᒶᒷᒸᒹᒺᒼᓂᓃᓄᓅᓇᓈᓋᓌᓍᓎᓏᓐᓕᓗᓚᓦᓧᓪᓫᓬᓮᓯᓰᓱᓲᓴᓵᓺᓾᓿᔅᔆᔐᔑᔓᔕᔖᔙᔚᔛᔜᔡᔢᔣᔤᔥᔩᔪᔫᔭᔮᔷᔼᔿᕆᕈᕉᕊᕋᕍᕐᕒᕓᕗᕘᕙᕚᕞᕠᕢᕦᕧᕨᕩᕫᕬᕮᕯᕰᕱᕲᕳᕴᕵᕶᕼᕾᕿᖀᖅᖆᖇᖏᖑᖒᖓᖔᖘᖙᖠᖫᖯᖰᖱᖲᖳᖴᖶᖸᖺᖻᖼᖽᖾᖿᗁᗂᗅᗋᗐᗔᗗᗚᗛᗜᗝᗞᗟᗠᗡᗢᗥᗦᗨᗩᗪᗫᗬᗭᗯᗰᗱᗲᗳᗴᗵᗷᗸᗹᗼᗽᗾᗿᘂᘉᘍᘎᘏᘐᘑᘒᘓᘔᘗᘘᘙᘜᘝᘢᘮᘳᘴᘹᘺᘻᘿᙀᙁᙅᙈᙊᙍᙎᙏᙐᙑᙒᙓᙔᙖᙗᙘᙙᙛᙜᙝᙞᙟᙡᙢᙣᙤᙥᙦᙧᙪᙫᙬ᙭ᚊᚠᚡᚢᚣᚤᚦᚨᚩᚪᚫᚬᚮᚱᚲᚳᚴᚵᚷᚹᚺᚻᚼᚾᚿᛁᛂᛃᛄᛆᛇᛈᛉᛊᛋᛍᛏᛐᛑᛒᛖᛗᛘᛚᛝᛞᛟᛣ᛫ᜀᜁᜂᜃᜄᜅᜆᜇᜈᜉᜊᜋᜌᜎᜏᜐᜑᜒᜓ᜔កខគឃងចឆជឈញដឋឌឍណតថទធនបផពភមយរលវឝឞសហឡអឣឥឦឧឨឩឪឫឬឭឮឯឰឱឲឳ឴ាិីឹឺុូួើឿៀេែៃោៅំះៈ៉៊់៌៍៎៏័៑្៓។៖ៗ៚᠌ᠠᠡᠢᠣᠤᠥᠦᠧᠨᠩᠪᠫᠬᠭᠮᠯᠰᠱᠲᠳᠴᠵᠶᠷᠸᠾᡃᡄᡅᡇᡉᡑᡕᡠᡤᡨᡩᡳᡵᢆᢚᢤᢨᣃᣄᤀᤁᤂᤃᤅᤆᤇᤈᤋᤌᤍᤎᤏᤐᤑᤒᤓᤔᤕᤖᤗᤘᤙᤛᤜᤠᤡᤢᤣᤥᤧᤩᤪᤰᤱᤴᤶᤷ᤻᥄ᥐᥑᥓᥔᥕᥖᥗᥙᥛᥜᥝᥞᥠᥡᥢᥣᥦᥨᥩᥪᥫᥭᥰᥱᥲᥴᦏᦒᨀᨂᨄᨅᨆᨈᨉᨊᨍᨏᨑᨒᨓᨔᨕᨖᨗᨙᨚᩎᬡᬥᬦᬧᬬᬯᬾ᭄ᮁᮂᮃᮄᮅᮌᮒᮓᮔᮕᮖᮙᮛᮜᮝᮞᮟᮤᮥᮨ᮪ᮼᮽᯇᯤᯩᯱᰄᰭᰯᰱᱚᱛᱜᱝᱞᱟᱠᱡᱢᱣᱤᱥᱦᱧᱨᱩᱫᱬᱭᱮᱯᱰᱱᱲᱳᱴᱵᱶᱷᱸᱹᱽᴀᴄᴅᴆᴇᴉᴊᴋᴍᴏᴑᴓᴖᴗᴘᴙᴚᴛᴜᴟᴠᴢᴥᴧᴨᴫᴬᴮᴰᴱᴲᴳᴴᴵᴶᴷᴸᴺᴻᴼᴽᴿᵀᵁᵅᵇᵏᵐᵔᵜᵞᵡᵩᵪᵯᵴᵵᵸᶒᶓᶔᶕᶜᶠᶢᶤᶨᶯᶰᶸᶻ᷊᷽᷿᷈᷉᷋ᷝᷞᷟᷧ᷾᷍ḀḁḂḃḄḅḆḇḈḉḊḋḌḍḎḏḐḑḒḓḔḕḖḗḘḙḚḛḜḝḞḟḠḡḢḣḤḥḦḧḨḩḪḫḬḭḮḯḰḱḲḳḴḵḶḷḸḹḺḻḼḽḾḿṀṁṂṃṄṅṆṇṈṉṊṋṌṍṎṏṐṑṒṓṔṕṖṗṘṙṚṛṜṝṞṟṠṡṢṣṤṥṦṧṨṩṪṫṬṭṮṯṰṱṲṳṴṵṶṷṸṹṺṻṼṽṾṿẀẁẂẃẄẅẆẇẈẉẊẋẌẍẎẏẐẑẒẓẔẕẖẗẘẙẚẛẜẝẞẟẠạẢảẤấẦầẨẩẪẫẬậẮắẰằẲẳẴẵẶặẸẹẺẻẼẽẾếỀềỂểỄễỆệỈỉỊịỌọỎỏỐốỒồỔổỖỗỘộỚớỜờỞởỠỡỢợỤụỦủỨứỪừỬửỮữỰựỲỳỴỵỶỷỸỹỺỻỼỽỾỿἀἁἂἃἄἅἆἇἈἉἌἍἏἐἑἒἓἔἕἘἙἛἜἝἠἣἤἥἧἨἩἪἬἭἯἰἱἲἳἴἵἶἸἹἼὀὁὂὃὄὈὉὋὐὓὔὕὖὗὙὛὝὠὣὦὧὮὯὰὴήὶὸὺὼᾀᾂᾃᾄᾆᾇᾊᾋᾌᾏᾐᾑᾕᾖᾗᾘᾝᾟᾤᾥᾬᾰᾱᾴᾶᾷᾸΆῂῆῊῐῑῒῖῡῢῥῦῨῬῳῴῶῷῺ–—‗‘’‚“”„†‡•…‧‰‹›※‼⁂ⁱ₎ₓ₥€₯⃒⃘⃚⃔⃕⃖⃗⃜⃝⃞⃟⃠⃡⃢⃣⃤⃦⃫⃬⃭⃮⃯⃧⃩ℂ℅ℇℑℒℓℛ℠™ΩℬℯℱℴⅅⅡⅢⅴ↯∂∑∞∩∫≈≠≡≤≥≦≧⊕⊰⊱⋁⋆⋋⋌⌣⎛⎝⎞⎠⎲⎵⎷⏎⏝⏠⑩⑫⑰ⒶⒷⒸⒺⒻⒿⓀⓂⓄⓊⓋⓌⓏⓐⓓⓖⓚⓛⓝⓟⓦⓨ⓫─━│┌┐└┘├┤┼═║╔╗╘╚╛╝╣╤╦╧╩╪╬╭╮╯╰▁▂▃▅▆▇█░▒▓▷►▼◁◄◇◊◒◔◘◡◢◤◪☀★☆☊☜☡☥☭☮☺☼☾♈♔♛♡♣♪✂✅✇✌✎✓✔✗✘✝✞✟✣✤✥✦✩✪✫✬✭✮✯✰✱✲✹✿❀❁❂❃❄❉❊❣❤❥❦❧❿➜➸⠀⣧ⱢⱤⱥⱦⱭⱮⱯⱾⱿⴇⴈⴌⴟⴰⴱⴲⴳⴴⴵⴶⴷⴸⴹⴺⴻⴼⴽⴾⴿⵀⵁⵂⵃⵄⵅⵆⵇⵈⵉⵊⵋⵍⵎⵏⵐⵒⵓⵔⵕⵖⵗⵘⵙⵚⵛⵜⵝⵞⵟⵠⵡⵢⵣⵤⵥⵧⵯⷡⷥⷦⷪⷭⷮⷯⷴ⺌、。々〆〈〉《》「」『』【】〘〙〜〤ぁあぃいぅうぇえぉおかがきぎくぐけげこごさざしじすずせぜそぞただちぢっつづてでとどなにぬねのはばぱひびぴふぶぷへべぺほぼぽまみむめもゃやゅゆょよらりるれろゎわゐゑをんゔゖゝゞァアィイゥウェエォオカガキギクグケゲコゴサザシジスズセゼソゾタダチヂッツヅテデトドナニヌネノハバパヒビピフブプヘベペホボポマミムメモャヤュユョヨラリルレロヮワヰヱヲンヴヵヶヷ・ーヽヾㄊㄎㄓㄝㄞㄨㄱㄴㄹㅁㅇㅈㅉㅍㅎㅐㅓㅔㅖㅗㅜㅡㅣㅤㆍ㊖㊣㋖㋛㋡㔶㕥㛄㣄㩧㩮㮈㺩䉀䑂䑓䕃䭓一丁丂七丅万丈三上下不与丑丒专且丕世丘丙业丛东丝丞丟両两严並丨个丫中丰串临丶丷丸丹为主丼丽丿乀乂乃乄久乇么义之乌乍乎乐乒乓乔乖乗乘乙乛乜九也习乡书买乱乳乾亀亂了予争事二于亐云互亓五井亖亗亘亙亚些亜亞亟亠亡亢交亥亦产亨亩享京亭亮亰亲亵亷人亻亼亽亾亿什仁仅仇仈今介仌仍从仏仓仔仕付仙仚仝仟代令以仨仪们仮仰仲件价仺任份企伈伉伊伍伏休众优伙会伝伞伟传伤伦伯伱伴伶伸伺似伽但位低住佐佑体何佖佘余佛作你佣佩佬佰佳佶使侃來例侍侏侑侖供依侞侠価侣侥侧侨侯侶便係促俄俊俐俗俙俚保俞俠信俣俪俬俭修俯俵俺俽倉個倍倒倖候倚借倡値倦倩倪倫倭倸倻值倾假偈偉偌偏做停健偩偲偳側偵偶偷偽傀傅傍傑傘備傢催傭傲傳債傷傻傾働像僑僕僖僚僡僮僰僱僵價僾儀億儉儍儒償儡優儷儸儿允元兄充兆先光克免兎児兒兔党兜入內全兩八公六兮兰共兲关兴兵其具典兹养兼兽冀冄内円冇冈冉冊冋册再冒冖写军农冠冢冥冧冨冬冭冯冰冲决冴冶冷冻冼冽净凄准凉凊凌凍减凘凛凜凝凞几凡凤処凪凯凰凱凳凸出击函刀刁刃刄分切刈刊刑划列刘则刚创初删判別利刪别刮到制券刹刺刻剀則削剌前剎剑剔剛剡剣剤副剱割剴創劇劉劍劏劑力办功加务劣动助努劫劬劭励劲劳効劼势勁勃勅勇勉勋勍勒動勘務勛勝勞募勢勤勲勳勵勻勿匀匂包匒匕化北匙匚匠匡匪匯匱匹区医匿區十千卄升午卉半卌华协卑卓協单卖南単博卜卝卞占卡卢卣卦卧卫卯印危即卵卷卽卿厂厄历厌厘厚原厠厤厦厨厭厲厳厶厷去叁参參叄又叉及友双反収发叔取受变叙叛叡口古句另只叫召叭叮可台史右叶号司叻叼吃各吇合吉吋同名后吏吐向吕吗君吟吡吥否吧含听吮启吱吳吴吵吸吹吻吼吾呀呂呆呇呈呉告呐呑呒呓呖呗员呢呦周呪呱味呵呼命咀咁咂咄咋和咏咐咔咕咖咘咚咣咩咪咯咲咳咽咿哀品哆哇哈哉哋响哎哒哓哔哟員哥哩哪哭哮哲唄唆唇唉唏唐唔唖唜唧售唯唱唲唹啄商啊問啓啟啡啤啦啵啸啼啾喀喃善喆喇喉喊喔喘喜喝喪喬單喰喱喵営喷喻嗎嗏嗖嗚嗜嗣嗦嗪嗫嗯嗱嘉嘎嘘嘚嘛嘜嘟嘠嘩嘭嘯嘲嘻嘿噌噗噛噜噠噢器噴噶噹嚇嚐嚕嚧嚮嚴嚼囉囊囍囗囚四囝回囟因囡团団囧园囯困図囹固国图圃圆圈國圍園圓圖團土圣圧在圭地圳场址坂均坊坎坏坐坑块坙坚坛坝坡坤坦坪坭坷垂型垚垠垢垣垫垲埃城埔埜域埴執培基埼堀堂堃堅堇堊堕堡堤堪堯堰報場堵堺塁塊塋塑塔塗塘塙塚塞塩填塱塲塵境墅墊墓増墙增墨墮墳墾壁壇壊壕壘壞壤士壮壯声壱売壳壶壷壹壺壽处备変夊夌复夏夕外夘多夛夜够夠夢大天太夫夬央夯失头夷夺奀奄奇奈奉奋奎奏奐契奔奕奖套奠奢奥奧奨奪奮女奴奵奶奸好如妃妄妆妇妍妏妒妖妗妘妙妝妤妥妨妩妮妳妹妺妻姆姉始姍姐姑姓委姗姚姜姝姨姫姬姲姳姵姶姷姸姿威娃娅娇娉娒娘娛娜娟娣娥娫娳娴婀婆婉婕婗婚婞婦婧婭婳婴婵婷媁媂媒媖媚媛媜媽嫁嫂嫌嫒嫙嫚嫣嫦嫩嫲嫻嬅嬉嬊嬋嬌嬡嬣嬤嬪嬰嬷嬸嬿孃孋子孑孔孖字存孙孛孜孝孟季孤学孩孫孬孱學孽宁它宅宇守安宋完宍宏宓宗官宙定宛宜宝实実客宣室宥宧宪宫宬宮宰宲宵家宸容宽宾宿寁寂寄寅密寇富寐寒寓寘寛寝寞察寡實寧審寫寬寮寯寰寳寵寶寸对寺寻导対寿封専射将將專尉尊尋對導小尐少尒尔尕尖尘尚尛尤尧尭就尸尹尺尻尼尽尾局屁层居屈届屋屍屏屐屑展屝属屠層屬屯山屺岁岄岐岑岚岛岡岩岫岬岭岱岳岸峇峠峡峤峥峨峪峭峮峯峰島峻崇崊崋崎崑崔崖崚崤崩崴崵嵋嵐嵘嵛嵜嵩嵬嵯嵻嶋嶌嶺嶼嶽巍巒巖巛川州巠巡巢巣工左巧巨巫差己已巳巴巷巻巾币市布帅帆师希帏帕帖帘帝帥带師席帮帯帰帳帶帷常帼帽幅幌幕幟幡幣幫干平年并幸幹幻幼幽幾广広庄庆床序库应底店庙庚府庞庠度座庫庭庵康庸廁廂廄廉廊廖廚廟廠廢廣廳廴延廷廸建廻廾廿开弁异弄弋弍弎式弐弑弒弓弔引弗弘弛弟张弥弦弩弯弱張強弸弹强弼弾彈彌彎彑归当录彗彡形彣彤彥彦彧彩彪彫彬彭彰影役彻彼彾往征径待很律後徐徑徒従得徙從御徦復循微徯徳徴徵德徹徽心忄必忆忌忍志忘忙忞忠忧快忱忲念忸忻忽怀态怎怒怖怜思怠怡急性怨怩怪怷怺总怿恆恋恐恒恕恛恢恥恨恩恬恭息恰恵恺悅悉悌悔悖悟悠悤悦悩悪悬悲悳悴悶情惇惊惑惘惜惟惠惡惣惪惯惰想惹惺愁愈愉意愚愛感愫愷愼愿慈慊態慌慎慕慘慜慢慣慧慨慮慰慶慷憂憎憐憔憤憧憫憬憲憶憾懂應懋懌懐懒懓懦懶懷懸懿戀戅戇戈戎戏成我戒或战戛戦戮戯戰戲戴戶户戸房所扁扆扇手才扎扑扒打托扛扣执扩扬扭扯扳扶批找承技抄把抒抓投抖抗折抚択抢护报抱抵抹押抽担拆拈拉拍拎拒拓拔招拜拝拡拥拨择括拯拱拳拼拽拾拿持指按挑挙挨挪振挺挽挾捌捏换捨据捲捷捺掃掄授掌排掘掛掞掠採探掣接控推措掬揁揉描提揖揚換握揪揮援揼損搜搬搭搵搶携摂摄摆摘摟摩摳摸摺撃撈撒撓撞撤撫播撮撲撳撼擁擂擇擊擋操擔擦擴擺攝攪支攵收攸改攻放政故效敉敌敏救敗教敢散敦敬数整敵敷數文斈斉斋斌斎斐斑斗料斜斡斤斧斩斬断斯新斳斷方於施斿旅旆旋旌旎族旖旗无既旤日旦旧旨早旬旭旱时旷旺旻旼昀昂昆昇昉昊昌明昏易昕昜星映春昧昨昭是昰昱昴昼显時晃晉晋晏晓晖晗晚晞晟晤晧晨普景晰晴晶智暁暄暇暈暉暐暑暖暗暘暢暧暫暮暴暹曄曇曈曉曓曖曙曜曦曰曲曳更曵書曹曺曻曼曽曾替最會月有朋服朔朕朗望朝期朣朧木朩未末本札术朱朴朵机朽杂权杆杉李杏材村杖杜杞束条杢杣来杨杭杯杰東杵杺松板极枋枏析枒林枘枚果枝枠枡枦枫枭枯枰架柁柃柄柊柏某柑柒染柔柘柚柜柞柠查柯柱柳柴柵査柾柿栁栂栃栄标栈栋栎树栓栖栗栝栞校栢栤栩栵样核根格栽桀桁桂桃案桉桊桌桐桑桒桓桔桜桝桟桢档桥桦桧桩桶梁梅梓梘梛條梟梠梢梦梧梨梭梯械梵梶梿棄棉棋棒棕棗棘棚棟棠棧森棱棻棿椀椅椋植椎椒椙椛検椰椽椿楊楒楓楚楜楠楡楢楧楨業楯楳極楷楸楹楼楽概榆榈榊榎榑榕榛榜榟榮榴榺槀槁槇構槌様槙槺槻槽樂樊樋樑樓樗標模樣権横樫樱樹樺樽橄橋橘橙橞機橡橫檀檎檔檜檩檪檬檳檸櫛櫟櫥櫲櫻欄欅權欖欠次欢欣欧欲欸欺欽款歆歌歐歡止正此步武歩歪歯歳歴歷歸死殇殉殊残殘殡殤殭殯殴段殷殺殻殼殿毅毉母毎每毓比毘毛毫毬氏民氓气氕気氛氢氣水氵氷永氹汀汁求汉汎汐汓汕汗汚汝江池污汤汪汰汲汶決汽汾沁沂沃沄沅沈沉沐沒沓沖沙沚沛没沢沧沪沫沬沭河沵沸油沺治沼況泉泊泋泓法泗泞泠泡波泣泥注泪泫泯泰泳泵泼泽洁洋洒洗洙洛洞津洧洨洪洫洮洱洲洵洸洹洺活洽派流浄浅浈测济浓浚浜浠浣浦浩浪浬浮浴海浸涁涂涅消涌涓涔涙涛涞涠润涩涯液涳涵涼淀淂淇淋淑淓淖淘淙淚淞淡淣淨淩淪淮淯深淳淵淸淺添淼渃清済渉渊渋渓渕渚渝渠渡渣渥渦温測渭港渴游渺渼渾湄湊湋湏湖湘湚湛湧湫湬湮湯湾湿満溈源準溜溝溟溢溥溦溧溪溫溯溱溶滄滇滉滋滐滑滔滕滙滝满滢滨滩滴滸滿漁漂漆漉漎漏漓演漠漢漣漩漪漫漬漸漾漿潇潋潑潓潔潘潛潜潟潤潭潮潺潼潾澁澄澌澍澎澐澔澜澡澤澧澪澰澱澳澹激濃濑濕濟濠濡濤濫濬濮濰濱濵濺瀅瀏瀚瀛瀟瀧瀨瀬瀾灌灏灑灘灜灝灣火灬灯灰灵灸灼災灿炉炎炒炖炙炜炫炭炮炳炸点為炼炽烂烈烏烘烛烝烟烤烦烨热烹烽焉焊焕焗焙焚焜無焦焯焰焱然焻焼煇煉煊煌煒煕煙煜煞煥煦照煩煬煮煱煵熄熈熊熔熙熟熠熨熭熱熹熽熾燁燃燄燈燊燎燐燒燕燚營燦燭燾燿爆爐爛爧爪爭爰爱爵父爷爸爹爺爻爽爾爿牆片版牌牙牛牟牡牧物牵特牽犀犬状犽狀狂狄狐狗狙狛狡狩独狭狮狱狸狼猎猛猜猟猡猥猩猪猫猬献猴猶猷猿獄獅獎獠獣獧獨獲獵獸獻玄率玉王玎玖玗玛玟玡玢玥玦玨玩玫玮环现玲玹玺玻珀珂珅珈珉珊珍珏珑珞珠珣珩班珮珳珺珽現琁球理琇琉琛琝琡琢琤琥琦琨琪琬琮琰琲琳琴琵琼琿瑀瑂瑄瑋瑚瑛瑜瑞瑟瑠瑤瑩瑪瑰瑱瑳瑶瑾璀璁璃璇璋璐璓璘璟璢璣璧璨環璸璽瓅瓊瓏瓔瓜瓢瓦瓶瓷甄甌甕甘甚甜生產産用甩甫田由甲申甴电男甸町画畈界畑畔留畝畠畢略畦番畫畯異畱畳當畹疇疋疍疏疑疗疫疯疲疼疾痔痕痛痞痧痴痹痺瘋瘦療癒癡癫癲癸発登發白百的皆皇皎皐皓皕皛皮皿盃盅盆盈益盎盏盐监盒盖盗盘盛盜盟盠盡監盤盧目盯盲直相盼盾省眉看県眞真眠眷眼眾着睛睜睡督睦睪睫睿瞎瞥瞬瞭瞳瞿矚矜矢知矩矫短矮石矶矿码砂研砕砥砰破砵砸硕硝硬确硲硴碌碍碎碑碓碕碗碧碩碹確碼磁磊磐磗磚磡磧磨磯礁礒示礼社祁祇祈祉祐祖祚祛祜祝神祟祢祤祥票祭祯祷祺祿禁禄禅禎福禤禧禪禮禰禹禺离禾禿秀私秉秋种科秒秘秝租秣秤秦积称移稀程税稔稗稙稚稜種稱稲稻稼稽稿穀穂穅穆積穎穏穐穗穣穩穴究穹空穿突窈窗窝窩窪窯竅竈立站竜竞竟章竣童端競竹竺笅笆笑笔笘笙笛笠符笨第笳笹筆筈等筋筍筑筒答策筛筝筠筩筬筱筵筽简箆箇箏箕箖算箜管箭箱箸節範篇築篝篠篤篥篭簑簗簡簾簿籃籌籍籏籐籔籟籠籣籬籲米籽籾粉粋粒粕粗粘粛粟粥粦粧粮粱粵粹精糀糊糕糖糟糠糧糯糸系紀約紅紋納紐紓純紗紘紙級紛素紡索紧紫累細紳紶紸紹紺終絃組絆絋経結絕絛絜絡絢給絮統絲絳絵絶絹綉經綕継続綜綠綢綣綨綪維綱網綴綵綸綺綽綾綿緊緋総緑緒線緣編緩緯緲練緹緻縁縄縈縓縛縢縣縫縱縹總繁繃繆織繡繣繩繪繭繽繾纈續纐纖纞红纤约级纪纬纭纯纱纲纳纵纶纷纸纹纽纾线练组绅细织终绍经绒结绘给绚络绝统绣绥继绩绪绫续绮绯维绵综绿缇缈缋缌缐缓缔缘缤缥缶缺罅罐罒罓罕罗罚罡罢罪置罰罵罷羀羅羈羊美羚羡羢群羨義羲羽羿翁翅翊翌翎習翔翘翟翠翡翩翫翰翱翲翹翻翼翾耀老考者耆而耐耕耗耘耜耨耳耶耽耿聂聆聊联聖聘聚聞聡聪聯聰聲聶職聽聾聿肁肃肆肇肉肌肖肘肚肛肝肠股肤肥肩肪肯育胃胆背胎胖胜胞胡胤胥胭胶胸能脂脅脆脇脈脉脑脖脚脩脸脹脾腊腕腥腦腩腮腰腱腸腹腾腿膀膏膓膚膜膝膠膳膽臂臉臖臣臥臧臨自臭至致臺臻臼舅與興舊舌舍舎舒舖舘舛舜舞舟舩航般舶船艇艚艦良色艳艶艷艸艹艺艾节芃芊芋芑芒芓芙芝芠芣芥芦芩芫芬芭芮芯花芳芴芷芸芹芽苅苇苍苏苑苓苕苗苛苟苠苡若苦苧苫苯英苹苺苾茁茂范茄茅茉茔茗茛茜茤茨茫茱茲茳茴茵茶茸茹荃荆草荊荍荏荒荔荘荟荡荣荭荳荷荻荼莉莊莎莓莘莙莛莜莣莨莪莫莱莲莳获莹莼菀菁菅菇菈菊菌菏菓菖菜菞菟菠菡菩華菰菱菲菸菻菽菿萄萊萌萍萓萝萠萢萤营萧萨萩萬萱落葆葉葑著葛葡董葦葫葬葭葱葳葵葶葺蒂蒋蒔蒙蒜蒞蒣蒨蒲蒸蒹蒻蒼蒽蓁蓉蓋蓏蓑蓓蓙蓜蓝蓥蓬蓮蓼蔆蔓蔗蔚蔟蔡蔣蔥蔦蔧蔭蔵蔺蔻蔼蕃蕉蕊蕎蕗蕙蕨蕫蕭蕲蕴蕷蕾薄薆薇薈薏薑薔薗薙薛薜薡薦薩薪薫薬薮薯薰藁藃藍藏藕藝藤藥藩藪藰藻蘆蘇蘊蘋蘏蘑蘓蘔蘭蘾蘿虄虎虐虑虔處虚虛虞號虫虹虾蚁蚂蚊蚪蚵蛇蛋蛍蛙蛟蛤蛭蛮蛯蜀蜂蜃蜊蜓蜚蜜蜡蜢蜥蜷蜻蝀蝃蝉蝌蝎蝙蝟蝠蝦蝪蝴蝶蝸螂螃融螞螢螺蟆蟑蟲蟷蟹蟻蠍蠔蠟蠡蠢蠻血衅衆行衍術街衛衝衞衡衣补表衫衬衮衰衿袁袆袈袋袓袖被袴裁裂裃装裏裔裕補裝裟裡裬裳裴裹製裾複褌褏褓褚褲襟襪襲西覀要覃覅覇見規視覚覧親観覺觀见观规觅视览觉角觜解触言訂計訊討訓託記訩訪設許訴訶証詐詔評詞詠詡試詩詮詰話詳詹詺誅誇誉誌認誒誓誘語誠說説読誰課誼調諄談請諌諏諒論諠諦諫諭諮諱諵諸諺諾謀謂謄謎謙謚講謝謴謹證識譙譚譜警議譲護譽譿讀讃變讐讓讚计订讨让训讯记讲讷许论访诀证评识诉诊诏译诒试诗诚话该详语诱说诶请诸诺读调谆谈谊谎谐谙谢谦谨谭谷豆豈豉豊豎豐豔豕豚象豪豫豬豭豹豺貅貓貔貝貞負財貢貧販貫貮貳貴買貸費貽貿賀賃資賈賊賓賛賜賞賠賢賣賦質賴購賽贀贄贈贝贞贡财贤账购贰贱贵贸费贺贻贼贾资赈赋赐赓赖赛赞赢赤赦赫走赳赴赵起超越趙趣足趴跃跋跌跑距跟跡跨跩路跳踏踞踩踪蹈蹟蹤蹦躅躍躑身躺車軌軍軒軟転軸軻軽較載輊輔輕輝輩輪輸輿轅轉轎轟车轨轩转轮软轶轻辅辈辉输辕辛辜辞辣辭辰農边辺辻込达辿迁迅过迈迎运近返还进远违连迟迦迩迪迫迭述迴迷迹迺追退送适逃逅逆选逊逍透逐逑途逖逗這通逝速造逢連週進逸逺逼逽遂遄遅遇遊運過遐道達違遗遙遜遞遠遢遣遥適遲遴選遺遼避邁邂還邉邊邋邏邑邓邝邢那邦邨邪邬邱邵邹邻郁郎郑郝郞郡部郭郵郷郺都郿鄉鄒鄔鄞鄥鄧鄭鄺酃酉酊酋配酒酔酢酥酩酬酵酷酸醉醋醍醐醒醜醫醬醸醺釆采釈釉释釋里重野量金釘釜針釡釣釧釨釼鈍鈐鈑鈕鈞鈣鈦鈮鈴鈺鈿鉃鉄鉅鉈鉛鉢鉱鉾銀銅銑銓銕銘銜銭銮銳鋆鋐鋒鋤鋪鋭鋰鋳鋼錄錋錐錒錕錚錠錡錢錦錫錬錯録錶鍆鍇鍊鍋鍛鍜鍬鍵鍶鍾鎂鎇鎊鎌鎔鎖鎛鎧鎬鎮鏆鏈鏋鏑鏗鏞鏟鏡鏵鏻鐘鐙鐵鑒鑓鑣鑫鑽针钊钕钚钜钟钡钢钥钦钧钮钰钱钲钶钸钻铁铃铎铛铠铤铧铨铭铮铵银铺链销锁锅锋锌锎锐锗锝锟锠锣锤锦锫键锲锴锶锺镁镅镇镒镔镖镜镫镭镱長长門閃閉開閑閒間閔閘閙関閣閬閲閻闆闇闊闒闘關门闪闭问闯闲间闷闹闻阀阁阅阌阎阑阗阙阚阜阝队阡阪阮防阳阴阿陀附际陆陈陌降限陞院陣除陨险陪陰陳陵陶陷陸険陽隅隆隈隊隋階随隐隔際隠隣隧隨險隱隳隴隷隹隻隼隽难隿雀雁雄雅集雇雉雋雌雍雏雑雕雙雛雜雞離難雨雪雯雲零雷電雾需霁霂霄霆震霈霉霊霍霏霓霖霜霞霧霭露霸霹靂靄靈靑青靓靖静靚靜非面革靭靳靴鞋鞍鞘鞠鞥韋韓韦韩韫韬韮音韵韶韻響頁頂頃順須頌預頒頓頔頗領頡頤頨頬頭頰頴頹頻頼顆題額顏顓顔顕願顛類顧顯页顶顺顽顾顿颂预领颉颍颐频颖题颜额颠風颯飄飆风飏飕飘飚飛飞食飠飢飯飲飴飼飽飾餃餅養餌餐餒餓餘館饅饒饗饪饭饮饰饺饼首香馜馥馨馬馮馳馴馷駁駄駆駒駕駝駱駿騎騏験騦騫騮騰騷驀驊驕驗驚驛驢马驰驴驷驻驾驿骄骆骏骑骗骨體高髙髪髭髮鬃鬆鬍鬚鬥鬮鬱鬼魁魂魃魄魅魇魈魉魍魏魑魔魚魯魰魷鮎鮑鮒鮨鮪鮫鮮鯉鯊鯛鯨鰂鰐鰻鱗鱻鱼鲁鲍鲜鲨鲸鳞鳥鳩鳯鳲鳳鳴鴇鴉鴨鴩鴫鴻鴾鴿鵜鵝鵤鵬鵲鵽鶏鶑鶴鷄鷇鷗鷲鷹鷺鸞鸟鸡鸢鸣鸥鸦鸭鸽鸾鸿鹂鹅鹌鹏鹑鹤鹰鹽鹿麂麈麒麓麗麟麥麦麵麺麻麼麽麿黃黄黍黎黑黒黔默黙黛點黟黨鼈鼎鼐鼓鼠鼻鼾齊齋齐齡齢齪齮齷龄龍龐龔龘龙龚龜龟ꀀꀆꀇꀈꀊꀋꀎꀒꀓꀘꀡꀤꀧꀪꀭꀷꀸꁅꁊꁌꁏꁕꁣꁧꁱꁲꁴꁻꂅꂑꂖꂚꂠꂦꂵꃅꃆꃔꃩꃲꃼꄙꄞꄟꅏꅐꅤꆂꆨꆰꆹꇃꇎꇖꇩꈚꈛꈤꈵꈼꉄꉓꉣꊐꊛꊼꋊꋒꋖꋪꋫꋬꌃꌅꌗꌚꌦꌩꍈꍌꍏꍛꍟꍩꎇꎭꏂꏄꏈꏝꏤꏹꏿꐈꐞꑀꑘꒌꓐꓑꓒꓓꓔꓕꓖꓗꓘꓙꓚꓛꓝꓞꓟꓠꓡꓢꓣꓤꓥꓦꓧꓨꓩꓪꓫꓬꓭꓮꓯꓰꓱꓲꓳꓴꓵꓶꓷꓸꓹꓽꔀꔁꔅꔉꔊꔋꔔꔖꔘꔚꔜꔝꔞꔠꔡꔪꔬꔭꔮꔰꔷꔹꔺꔻꔽꕂꕔꕕꕗꕘꕤꕥꕬꕭꕯꕷꕹꕺꕻꖀꖍꖒꖘꖛꖜꖞꖧꖯꖲꖴꖵꖸꖹꖻꖼꖽꗃꗄꗈꗋꗍꗛꗜꗝꗞꗟꗣꗥꗮꗯꗰꗴꗶꘂꘈꘌꘐꘑꘒꘖꘘꘜꘝꙨꙮ꙰꙲ꜭꝄꝅꝫꝮꝯꞀꞍꞪꞫꞬꞮꞰꞱꞲꠀꠇꠎꠖꠝꠞꠡꠣꠤꠥꠦꡰꤋꤎꤚꤢꤧꤨ꤬꤭ꤶꦄꦆꦌꦏꦒꦔꦕꦚꦠꦤꦥꦦꦩꦪꦫꦮꦱꦲ꦳ꦴꦶꦸꦺꦿ꧀꧁꧆ꧼꧾꪋꪔꪖꪜꪲꪳꫛꫝ꫞ꫪꭰꭱꭲꭳꭴꭵꭶꭷꭸꭹꭺꭻꭼꭽꭾꭿꮀꮁꮂꮃꮄꮅꮆꮇꮈꮉꮊꮋꮍꮎꮏꮐꮑꮒꮓꮔꮕꮖꮗꮘꮙꮚꮛꮜꮝꮞꮟꮠꮡꮢꮣꮤꮥꮦꮧꮨꮩꮪꮫꮬꮭꮮꮯꮰꮱꮲꮳꮴꮵꮶꮷꮸꮹꮺꮻꮼꮽꮾꮿꯀꯁꯂꯃꯄꯅꯆꯇꯈꯉꯊꯋꯌꯍꯎꯏꯐꯑꯒꯓꯔꯕꯖꯗꯘꯚꯜꯝꯞꯟꯠꯡꯢꯣꯤꯥꯦꯧꯨꯩꯪ꯭가간갈감갑강같개갠갬갯갸거건걸검겉게겐겔겜겠겨격결겸경계고곡곤곰곳공과곽관괂광교구국군굴궁궇권귀규균그극근글금기긴길김깃깊깐깜꺼께껫꼬꼴꽃꾼꿈끄끌나낙난낟날남납낭낳내낸낼냇냉냐냔너넛네넨넬넴넷녀년녈녕노논녿놀놈놋농놏높놓뇌뇨뇸누눈눌느는늘늙늡늬니닉닌닐님닛닜다단닫달담당닽대댁댄댐댜댠더덕덟데덱델뎌도독돈돌돗동될두둔둘둠둥듀듗드득든듣들딈디딕딘딜딧딩딴떠떰떼또똑뚱뜸띠띰라락란랂랄랅람랍랏랑랒랔랗래랜랟랠랫랭랰랴랼럄량러럭런럼렁렂레렉렌렐렘렛렜렣려력련령례로록론롬롯롱롲롸료룡루룩룬룰룽룾뤠류륜률륭르른를름릉릏릐리릭린릳릴림립릿링맂맆마막만많맏말맘맛망맞맠맡맣매맥맨맹맺먀먕머먼먿멋멍멓메멘멜면멶명모목몪몬몯몰몹못몽뫀뫼묘묨묭묲묳무묵묶문묻뭏므믤미믹민믿밀밋밍밑바박반받발밧방밯배백밴밸뱅버번벌범법벗벙벚베벤벨벳변별병보복본봄봅봉봐부북분불붓붕브븍븐블븧비빅빆빈빌빛빨뿌뿐뿔쁘쁜쁨사산살삼샀상샅새색샌샐샘샛생샤샬샴샹서석선설섭섯성세섹센셀셈셉셔셜셰셸소속손솔송솧솨쇼쇽숀숒숓수숙순술숩숭숸쉐슈슐스슥슨슬슴승시식싞신실싫심십싶싸쌍쌰써썬썽쎌쑹쓰씨씬씸씽아악안앉앋알암압앗앙앞앟애액앤앨앰야약얀얌얏얐양얗얘얜얲어언얼엄업없었엉엏에엔엘엠엦엩여역연열영예옏옐오옥온옫올옴옹옿와완왈왑왓왔왕외왼요욕욘욜용우욱운욷울움웃웅워원월웡웨웬위윅윈윌유육윤율으은읃을음응의이익인일읽임입있잉잌자작잔잘잠장재잭잼잿쟁쟆쟈저적전젊점젓정제젠젤젬져조족종좋좌죠주죽준줄중줘쥍쥐쥔쥬즈즌즐증지직진질짐집짖짜짬째쨔쨨쪽쭈쯔찌차착찬찰참창챀채책천철첨청체첸첻첼쳉쳐초촌촞최추축춘출충취츄츠츼치친칠침카칼캉캔캠커컨케켄켈켓켙켜켱켸코콜콤쿳퀴큐큓크큰큺킊키킨킬킴킿타탁탄탈탉탐탕태택탭탱탷터털테텍텐텔템톄토톤톨톰통투툴튜튠튤튬트튼틀티틴팀팃팅파팍판팑팔패팩팬퍼퍽펀펄페펠펴편평폐포폭폴표푸풀품풋풍퓨픀프픈플피필핏핑하학한핟할함합핫항해핸햄햇했행향허헌헐험헤헥헨헬헷혀혁현혈협형혜호혼홀홍화확환활황회횡효횬후훈훌훨휘휴휸흋흐흑흔흟흠흣흥희흱히힌힏힐힘﨑ﬓﬔﬕﬖﬗﬠﬡﬣﬦﬧﬨשּׂאַאָדּהּוּיּלּמּסּצּקּשּתּפֿﭏﭐﭑﭒﭓﭔﭕﭖﭗﭘﭙﭚﭛﭜﭝﭞﭟﭠﭡﭢﭣﭤﭥﭦﭧﭨﭩﭪﭫﭬﭭﭮﭯﭰﭱﭲﭳﭴﭵﭶﭷﭸﭹﭺﭻﭼﭽﭾﭿﮀﮁﮂﮃﮄﮅﮆﮇﮈﮉﮊﮋﮌﮍﮎﮏﮐﮑﮒﮓﮔﮕﮖﮗﮘﮙﮚﮛﮜﮝﮞﮟﮠﮡﮢﮣﮤﮥﮦﮧﮨﮩﮪﮫﮬﮭﮮﮯﮰﮱﯓﯔﯕﯖﯗﯘﯙﯚﯛﯜﯝﯞﯟﯠﯡﯢﯣﯤﯥﯦﯧﯨﯩﯼﯽﯾﯿﰎﰗﰲﱏﱙﱞﱟﱠﱡﱢﱯﲌﲕﲛﲝﲠﲭﳊﳌﳏﳒﳙﳣﳩﳪﳲﳳﳴﳼﴼﴽ﴾﴿ﶊﷲﷳﷴﷶﷸﷺﷻ︎️︶︻ﹰﹱﹲﹳﹴﹶﹷﹸﹹﹺﹻﹼﹽﹾﹿﺀﺁﺂﺃﺄﺅﺆﺇﺈﺉﺊﺋﺌﺍﺎﺏﺐﺑﺒﺓﺔﺕﺖﺗﺘﺙﺚﺛﺜﺝﺞﺟﺠﺡﺢﺣﺤﺥﺦﺧﺨﺩﺪﺫﺬﺭﺮﺯﺰﺱﺲﺳﺴﺵﺶﺷﺸﺹﺺﺻﺼﺽﺾﺿﻀﻁﻂﻃﻄﻅﻆﻇﻈﻉﻊﻋﻌﻍﻎﻏﻐﻑﻒﻓﻔﻕﻖﻗﻘﻙﻚﻛﻜﻝﻞﻟﻠﻡﻢﻣﻤﻥﻦﻧﻨﻩﻪﻫﻬﻭﻮﻯﻰﻱﻲﻳﻴﻵﻶﻷﻸﻹﻺﻻﻼ！（）＊－．ＡＢＣＤＥＦＧＨＩＪＫＬＭＮＯＰＲＳＴＵＷＸＹＺａｂｃｄｅｆｇｈｉｊｋｌｍｎｏｐｑｒｓｔｕｖｗｘｙｚ～｡､ｧｨｰｱｲｴｶｺｻｼｽﾂﾉﾊﾌﾐﾒﾕﾗﾘﾙﾚﾛﾝﾞﾠﾶ�𝓐𝓓𝓗𝓘𝓚𝓛𝓝\n",
      "\n",
      "Number of target classes: 19:\n",
      "Caribbean, Eastern Asia, South-eastern Asia, Western Europe, Eastern Europe, Central Asia, Southern Europe, Melanesia, Northern Europe, Western Asia, Southern Africa, Middle Africa, Western Africa, Central America, Northern America, Northern Africa, Eastern Africa, South America, Southern Asia\n"
     ]
    }
   ],
   "source": [
    "train_data = NameNationalityDataStream(\n",
    "    data_file='./data/train.csv',\n",
    "    chunksize=10_000,\n",
    "    maximum_name_length=MAXIMUM_NAME_LENGTH,\n",
    "    vocabulary=VOCABULARY,\n",
    "    country_codes=COUNTRY_CODES,\n",
    "    country_mapping=COUNTRY_MAPPING\n",
    ")\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameNationalityData(Dataset):\n",
    "    \"\"\"\n",
    "    A simple Dataset that loads data from a single CSV file containing name and nationality.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        Path to the CSV file.\n",
    "    maximum_name_length : int\n",
    "        Number of characters after which names in input get truncated\n",
    "    vocabulary : str\n",
    "        String of all unique characters in vocabulary\n",
    "    country_codes : list\n",
    "        List of all unique country codes in dataset\n",
    "    country_mapping : dict\n",
    "        Dictionary of alpha2 to target category mapping (e.g. UN region)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_file: str,\n",
    "        maximum_name_length: int,\n",
    "        vocabulary: str,\n",
    "        country_codes: list,\n",
    "        country_mapping: dict\n",
    "    ) -> None:\n",
    "        self.data_file = data_file\n",
    "        self.maximum_name_length: int = maximum_name_length\n",
    "        self.vocabulary: str = vocabulary\n",
    "        self.country_codes: list = country_codes\n",
    "        self.country_mapping: dict = country_mapping\n",
    "        self.padding_index: int = 0\n",
    "\n",
    "        # read data from csv files\n",
    "        df = pd.read_csv(self.data_file)\n",
    "        print(f'Dataset has {len(df)} records.')\n",
    "\n",
    "        # generate input mappings (character to index and vice versa)\n",
    "        (self.character_to_index,\n",
    "         self.index_to_character,\n",
    "         self.vocabulary_length) = self._generate_name_mapping(\n",
    "            self.vocabulary\n",
    "        )\n",
    "        \n",
    "        # generate output mappings (alpha2 to index as well as class (e.g. UN region) to index and vice versa)\n",
    "        (self.class_to_index,\n",
    "         self.index_to_class,\n",
    "         self.alpha2_to_index,\n",
    "         self.number_of_classes) = self._generate_country_mapping(\n",
    "            self.country_codes,\n",
    "            self.country_mapping\n",
    "        )\n",
    "\n",
    "        # encode names as padded index tensors\n",
    "        self.X, self.sequence_lengths = self._encode_name(\n",
    "            df['name'].to_list()\n",
    "        )\n",
    "\n",
    "        # encode countries as one-hot index tensors\n",
    "        self.y = self._encode_country(\n",
    "            df['alpha2'].to_list()\n",
    "        )\n",
    "\n",
    "    def _generate_name_mapping(self, vocabulary):\n",
    "        \"\"\"\n",
    "        Each character of the vocabulary is assigned an integer index, starting at 1 so that 0 can be \n",
    "        used as a padding index. The vocabulary is a list of unique characters generated from the dataset.\n",
    "        This method also prints out the vocabulary and vocabulary length.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        vocabulary : str\n",
    "            A string of unique characters generated from the input dataset.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple of (dict, dict, int):\n",
    "            ctoi : dict\n",
    "                Mapping from character to integer index.\n",
    "            itoc : dict\n",
    "                Mapping from integer index back to character.\n",
    "            vocabulary_length : int\n",
    "                The number of unique characters in vocabulary.\n",
    "        \"\"\"\n",
    "        vocabulary_length = len(vocabulary)\n",
    "        print(f\"Vocabulary of length {vocabulary_length}:\\n{vocabulary}\")\n",
    "        ctoi = {c:i for i, c in enumerate(vocabulary, 1)} # start enumeration at 1 because 0 is padding index\n",
    "        itoc = {i:c for i, c in enumerate(vocabulary, 1)}\n",
    "        return ctoi, itoc, vocabulary_length\n",
    "    \n",
    "    def _generate_country_mapping(self, country_codes, country_mapping):\n",
    "        \"\"\"\n",
    "        Generate mappings between target classes and their indices based on country codes.\n",
    "\n",
    "        This method creates three mappings:\n",
    "        - A mapping from each target class (e.g., UN region) to a unique index (starting at 1,\n",
    "            since index 0 is reserved for padding).\n",
    "        - The inverse mapping from these indices back to the target classes.\n",
    "        - A mapping from each country code in the provided list to the corresponding class index,\n",
    "            as determined by the country_mapping dictionary.\n",
    "\n",
    "        Additionally, it calculates the total number of distinct target classes and prints this number\n",
    "        along with a list of the target classes.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        country_codes : list\n",
    "            A list of all country codes present in the dataset.\n",
    "        country_mapping : dict\n",
    "            A dictionary mapping each country code to its target class.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple of (dict, dict, dict, int):\n",
    "            class_to_index : dict\n",
    "                Mapping from target class to its unique index.\n",
    "            index_to_class : dict\n",
    "                Mapping from index to target class.\n",
    "            alpha2_to_index : dict\n",
    "                Mapping from country codes to their corresponding class indices.\n",
    "            number_of_classes : int\n",
    "                The total number of distinct target classes.\n",
    "        \"\"\"\n",
    "        output_classes = set(country_mapping.values())\n",
    "        number_of_classes = len(output_classes)\n",
    "        print(f'Number of target classes: {number_of_classes}:\\n{\", \".join(output_classes)}')\n",
    "        class_to_index = {c:i for i, c in enumerate(output_classes, 1)} # start enumeration at 1 because 0 is padding index\n",
    "        index_to_class = {i:c for c, i in class_to_index.items()}\n",
    "        alpha2_to_index = {country: class_to_index[country_mapping[country]] for country in country_codes}\n",
    "        return class_to_index, index_to_class, alpha2_to_index, number_of_classes \n",
    " \n",
    "    def _encode_name(self, seq):\n",
    "        \"\"\"\n",
    "        Encodes a single string or a list of strings into integer indices based on `self.character_to_index`,\n",
    "        replacing unmapped characters with `self.padding_index`. Each encoded sequence is then padded\n",
    "        to `self.maximum_name_length`, and the original (unpadded) lengths are recorded.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        seq : str or list of str\n",
    "            The input string(s) to be converted.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple of (torch.Tensor, torch.Tensor):\n",
    "            If input is a single string:\n",
    "                padded_tensor : torch.Tensor of shape (self.maximum_name_length,)\n",
    "                sequence_length : torch.Tensor (scalar) indicating the original length\n",
    "            If input is a list of strings:\n",
    "                padded_tensors : torch.Tensor of shape (batch_size, self.maximum_name_length)\n",
    "                sequence_lengths : torch.Tensor of shape (batch_size,) indicating the original lengths\n",
    "        \"\"\"\n",
    "        assert isinstance(seq, (str, list)), \"Input must be string or list of strings\"\n",
    "        if isinstance(seq, str):\n",
    "            # Process single string without wrapping it in a list.\n",
    "            encoded = [self.character_to_index.get(char, self.padding_index) for char in seq]\n",
    "            seq_len = len(encoded)\n",
    "            padded_tensor = torch.full((self.maximum_name_length,), self.padding_index, dtype=torch.int32)\n",
    "            max_len = min(seq_len, self.maximum_name_length)\n",
    "            padded_tensor[:max_len] = torch.tensor(encoded[:max_len], dtype=torch.int32)\n",
    "            return padded_tensor, torch.tensor(max_len, dtype=torch.int32)\n",
    "        \n",
    "        else:  # seq is a list of strings\n",
    "            encoded_input = []\n",
    "            for s in seq:\n",
    "                assert isinstance(s, str), \"Each element in the list must be a string\"\n",
    "                encoded_input.append([self.character_to_index.get(char, self.padding_index) for char in s])\n",
    "            sequence_lengths = torch.tensor(\n",
    "                [min(len(encoding), self.maximum_name_length) for encoding in encoded_input],\n",
    "                dtype=torch.int32\n",
    "            )\n",
    "            batch_size = len(encoded_input)\n",
    "            padded_tensors = torch.full(\n",
    "                (batch_size, self.maximum_name_length),\n",
    "                self.padding_index,\n",
    "                dtype=torch.int32\n",
    "            )\n",
    "            for i, encoding in enumerate(encoded_input):\n",
    "                seq_len = len(encoding)\n",
    "                max_len = min(seq_len, self.maximum_name_length)\n",
    "                padded_tensors[i, :max_len] = torch.tensor(encoding[:max_len], dtype=torch.int32)\n",
    "            \n",
    "        return padded_tensors, sequence_lengths\n",
    "\n",
    "    def _decode_name(self, seq_tensor):\n",
    "        \"\"\"\n",
    "        Decodes a 1D or 2D tensor of integer indices into characters using the `self.index_to_character` mapping.\n",
    "        \n",
    "        - If `seq_tensor` is 1D (shape: [N]), it decodes a single sequence of characters.\n",
    "        - If `seq_tensor` is 2D (shape: [B, N]), it decodes multiple sequences (one per row).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        seq_tensor : torch.Tensor\n",
    "            A 1D or 2D tensor of integer indices.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list of str:\n",
    "            If the input is 1D, returns a single-element list with the decoded name string.\n",
    "            If the input is 2D, returns a list of decoded names, one per row.\n",
    "        \"\"\"\n",
    "        if not isinstance(seq_tensor, torch.Tensor):\n",
    "            raise TypeError(\"seq_tensor must be a torch.Tensor of integer indices.\")\n",
    "        if seq_tensor.dim() == 1:\n",
    "            return [''.join([self.index_to_character.get(int(idx), '') for idx in seq_tensor])]\n",
    "        elif seq_tensor.dim() == 2:\n",
    "            decoded_sequences = []\n",
    "            for row in seq_tensor:\n",
    "                decoded_sequences.append(''.join([self.index_to_character.get(int(idx), '') for idx in row]))\n",
    "            return decoded_sequences\n",
    "        else:\n",
    "            raise ValueError(\"seq_tensor must be a 1D or 2D tensor of integer indices.\")\n",
    "\n",
    "    def _encode_country(self, country_input):\n",
    "        \"\"\"\n",
    "        Encode a country code or a list of country codes into one-hot vectors.\n",
    "\n",
    "        This method maps the input country code(s) to their corresponding indices using\n",
    "        `self.alpha2_to_index`. If a country code is not found in the mapping, the padding\n",
    "        index (`self.padding_index`) is used. The resulting indices are then converted into\n",
    "        one-hot encoded tensors with a dimensionality of `self.number_of_classes + 1` (to account\n",
    "        for the padding index).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        country_input : str or list of str\n",
    "            A single country code or a list of country codes.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        encoded_tensors : torch.Tensor\n",
    "            A tensor containing the one-hot encoded representation(s) of the input.\n",
    "        \"\"\"\n",
    "        assert isinstance(country_input, (str, list)), 'Input must be string or list of strings'\n",
    "        if isinstance(country_input, str):\n",
    "            encoded_output = self.alpha2_to_index.get(country_input, self.padding_index)\n",
    "        elif isinstance(country_input, list):\n",
    "            encoded_output = []\n",
    "            for c in country_input:\n",
    "                assert isinstance(c, str), 'Input must be string or list of strings'\n",
    "                encoded_output.append(self.alpha2_to_index.get(c, self.padding_index))\n",
    "        index_tensors = torch.tensor(encoded_output, dtype=torch.int64)\n",
    "        encoded_tensors = F.one_hot(index_tensors, num_classes=self.number_of_classes+1).to(torch.float32)\n",
    "        return encoded_tensors      \n",
    "\n",
    "    def _decode_country(self, country_code_tensor):\n",
    "        \"\"\"\n",
    "        Decodes a 1D or 2D one-hot-encoded tensor into its corresponding country code strings.\n",
    "\n",
    "        For a 1D tensor (shape: [num_classes]), it finds the index of the maximum value \n",
    "        (the argmax) and returns a list containing the corresponding country code.\n",
    "\n",
    "        For a 2D tensor (shape: [batch_size, num_classes]), it applies the same argmax \n",
    "        operation along each row, returning a list of country codes for the entire batch.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        country_code_tensor : torch.Tensor\n",
    "            A 1D or 2D tensor representing one-hot-encoded country codes.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list of str\n",
    "            - If the input is 1D, returns a single-element list with the decoded country code.\n",
    "            - If the input is 2D, returns a list of decoded country codes, one per row.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        TypeError\n",
    "            If `country_code_tensor` is not a torch.Tensor.\n",
    "        ValueError\n",
    "            If `country_code_tensor` is neither 1D nor 2D.\n",
    "        \"\"\"\n",
    "        if not isinstance(country_code_tensor, torch.Tensor):\n",
    "            raise TypeError(\"country_code_tensor must be a torch.Tensor of integer indices.\")\n",
    "        if country_code_tensor.dim() == 1:\n",
    "            return [self.index_to_class.get(torch.argmax(country_code_tensor).item(), 'Unknown')]\n",
    "        elif country_code_tensor.dim() == 2:\n",
    "            decoded_output = []\n",
    "            for encoding in country_code_tensor:\n",
    "                index = torch.argmax(encoding).item()\n",
    "                decoded_output.append(self.index_to_class.get(index, 'Unknown'))\n",
    "            return decoded_output\n",
    "        else:\n",
    "            raise ValueError(\"country_code_tensor must be a 1D or 2D tensor of integer indices.\")\n",
    "         \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "        sequence_length = self.sequence_lengths[idx]\n",
    "        return (X, y, sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 4882176 records.\n",
      "Vocabulary of length 11658:\n",
      " !#$%&()*-./:;<=ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}¡¢£¤¥¦§¨©ª«¬®¯°±´µ¶·¸º»¼½¾¿ÀÁÂÃÄÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖ×ØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõöøùúûüýþÿĀāĂăĄąĆćĈĉĊċČčĎďĐđĒēĔĕĖėĘęĚěĜĝĞğĠġĢģĤĥĦħĨĩĪīĬĭĮįİıĲĳĴĵĶķĸĹĺĻļĽľĿŀŁłŃńŅņŇňŉŊŋŌōŎŏŐőŒœŔŕŖŗŘřŚśŜŝŞşŠšŢţŤťŦŧŨũŪūŬŭŮůŰűŲųŴŵŶŷŸŹźŻżŽžſƀƁƂƃƄƅƆƇƈƉƊƋƌƍƎƏƐƑƒƓƔƕƖƗƘƙƚƛƜƝƞƟƠơƢƣƤƥƦƧƨƩƪƫƬƭƮƯưƱƲƳƴƵƶƸƹƺƻƼƽƾƿǀǂǅǆǍǎǏǐǑǒǓǔǕǖǗǘǙǚǛǜǝǞǟǠǡǢǣǤǥǦǧǨǩǪǫǬǭǮǯǰǳǴǵǶǷǸǹǺǻǼǽǾǿȀȁȂȃȄȅȆȇȈȉȊȋȌȍȎȏȐȑȒȓȔȕȖȗȘșȚțȜȝȞȟȠȡȢȣȤȥȦȧȨȩȪȫȬȭȮȯȰȱȲȳȴȵȶȷȸȹȺȻȼȽȾȿɀɃɄɅɆɇɈɉɊɋɌɍɎɏɐɑɒɓɔɕɖɗɘəɚɛɜɝɞɟɠɡɢɣɤɥɦɧɨɩɪɫɭɮɯɱɲɳɴɵɶɷɸɹɺɽɾɿʀʁʂʃʄʅʆʇʈʉʊʋʌʍʎʏʐʑʒʓʘʙʚʛʜʝʞʟʠʡʢʥʩʬʭʮʯʰʳʹʼʾˆˇˎː˘˚˛˜˟ˡˢˣ˫̴̵̶̷̸̡̢̧̨̛̖̗̘̙̜̝̞̟̠̣̤̥̦̩̪̫̬̭̮̯̰̱̲̳̹̺̻̼͇͈͉͍͎̀́̂̃̄̅̆̇̈̉̊̋̌̍̎̏̐̑̒̓̔̽̾̿͂͆͊͋͌̕̚ͅ͏͓͔͕͖͙͚͐͑͒͗͛ͣͤͥͦͧͨͩͪͫͬͭͮͯ͘͜͟͢͝͞͠͡ͶͷͺͼͽͿΆΈΉΊΌΎΏΐΑΒΓΔΕΖΗΘΙΚΛΜΝΞΟΠΡΣΤΥΦΧΨΩΪΫάέήίΰαβγδεζηθικλμνξοπρςστυφχψωϊϋόύώϏϐϑϒϓϔϕϖϗϘϙϚϛϜϝϢϥϧϨϩϪϫϭϯϲϳϵϺϻϾϿЀЁЂЃЄЅІЇЈЉЊЋЌЍЎЏАБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдежзийклмнопрстуфхцчшщъыьэюяѐёђѓєѕіїјљњћќѝўџѠѡѢѣѥѦѧѨѩѪѫѬѭѮѯѰѱѲѳѴѵѶѷѺѻѼѽѾѿҁ҃҄҅҆҇҈҉ҊҋҍҎҏҐґҒғҔҕҖҗҘҙҚқҜҝҞҟҠҡҢңҤҥҦҧҨҩҪҫҬҭҮүҰұҲҳҴҵҶҷҸҹҺһҼҽҾҿӀӁӂӃӄӆӇӈӉӊӍӎӏӐӑӒӓӕӗӘәӚӛӝӟӠӡӢӣӤӥӦӧӨөӪӫӭӮӯӱӲӳӵӶӷӻӼӽӿԀԁԂԃԄԅԆԇԊԋԌԍԎԏԑԔԕԖԗԚԛԱԲԳԴԵԶԷԸԹԺԻԼԽԾԿՀՁՂՃՄՅՆՇՈՉՊՋՌՍՎՏՐՑՒՓՔՕՖՙ՚՜՞աբգդեզէըթժիլխծկհձղճմյնշոչպջռսվտրցւփքօֆև։֊ְֱֲֳִֵֶַָֹֺֻּ֮֔֙֟֫־ֿׁׂ׆ׇאבגדהוזחטיךכלםמןנסעףפץצקרשתװױײ׳״،؍؏ؘؙؚؐؑؒؓؔؕؖ؛؞؟ؠءآأؤإئابةتثجحخدذرزسشصضطظعغػؼؽؾؿـفقكلمنهوىيًٌٍَُِّْٕٖٜٓٔٗ٘ٙٚٛٝٞ٪٫٬٭ٮٯٰٱٲٳٴٵٶٷٸٹٺٻټٽپٿڀځڂڃڄڅچڇڈډڊڋڌڍڎڏڐڑڒړڔڕږڗژڙښڛڜڝڞڟڠڡڢڣڤڥڦڧڨکڪګڬڭڮگڰڱڲڳڴڵڶڷڸڹںڻڼڽھڿۀہۂۃۄۅۆۇۈۉۊۋیۍێۏېۑےۓ۔ەۖۗۘۙۚۛۜ۞ۣ۟۠ۡۢۤۥۦ۪ۭۧۨ۫۬ۮۯۺۻۼ۽ۿ܀܃ܐܑܒܓܔܕܖܗܘܙܚܛܜܝܞܟܠܡܢܣܤܥܦܧܨܩܪܫܬܭܸܹܼ݂݄݆݈ܰܲܳܵܶܺܽܿ݁݃݅݇݉݊ݐݑݒݓݔݕݖݗݘݙݚݛݜݝݞݟݠݡݢݣݤݥݦݧݨݩݪݫݬݭݯݰݱݲݳݴݶݷݸݹݺݻݼݽݾݿހށނރބޅކއވމފދތލގޏސޑޒޓޔޕޖޗޘޙޚޛޜޝޞޟޠޢޣޤަާިީުޫެޭޮޯްޱߊߋߌߍߎߏߐߒߓߔߕߖߗߘߙߚߛߜߝߞߟߠߡߢߣߤߥߦ߲߫߬߭߮߰߱ߴߺࠃࡀࡃࡅࡉࡋࡌࡎࣰࣲࣩࣥࣨ࣪࣫ࣳࣵࣷࣸँंःअआइईउऊऋऌऍऎएऐऑऒओऔकखगघङचछजझञटठडढणतथदधनऩपफबभमयरऱलळऴवशषसहऻ़ऽािीुूृॄॅॆेैॉॊोौ्ॏॐ॒॑॓॔ॕॖॗख़ड़ढ़ॠॡॢॣ।॥॰ॱॲॶॼঁংঃঅআইঈউঊঋঌএঐওঔকখগঘঙচছজঝঞটঠডঢণতথদধনপফবভমযরলশষসহ়ঽািীুূৃৄেৈোৌ্ৎৗড়য়ৠৡৢৣৰৱਁਂਃਅਆਇਈਉਊਏਐਓਔਕਖਗਘਙਚਛਜਝਞਟਠਡਢਣਤਥਦਧਨਪਫਬਭਮਯਰਲਵਸ਼ਸਹ਼ਾਿੀੁੂੇੈੋੌ੍ੑਖ਼ਜ਼ੜੰੱੲੳੴੵઁંઃઅઆઇઈઉઊઋઌઍએઐઑઓઔકખગઘઙચછજઝઞટઠડઢણતથદધનપફબભમયરલળવશષસહ઼ઽાિીુૂૃૄૅેૈૉોૌ્ૐૠૣଁଂଃଅଆଇଈଉଊଋଏଐଓଔକଖଗଘଙଚଛଜଝଞଟଠଡଢଣତଥଦଧନପଫବଭମଯରଲଳଵଶଷସହ଼ଽାିୀୁୂୃୄେୈୋୌ୍ୟୱஂஃஅஆஇஈஉஊஎஏஐஒஓஔகஙசஜஞடணதநனபமயரறலளழவஶஷஸஹாிீுூெேைொோௌ்ௐௗఁంఃఅఆఇఈఉఊఋఎఏఐఒఓఔకఖగఘఙచఛజఝఞటఠడఢణతథదధనపఫబభమయరఱలళవశషసహఽాిీుూృౄెేైొోౌ్ౖౙౠౢಂಃಅಆಇಈಉಊಋಌಎಏಐಒಓಔಕಖಗಘಙಚಛಜಝಞಟಠಡಢಣತಥದಧನಪಫಬಭಮಯರಱಲಳವಶಷಸಹ಼ಾಿೀುೂೃೆೇೈೊೋೌ್ೕೖೠೡംഃഅആഇഈഉഊഋഎഏഐഒഓഔകഖഗഘങചഛജഝഞടഠഡഢണതഥദധനപഫബഭമയരറലളഴവശഷസഹഺഽാിീുൂൃൄെേൈൊോൌ്ൗൺൻർൽൾංඃඅආඇඈඉඊඋඌඍඏඐඑඒඓඔඕඖකඛගඝඞඟචඡජඣඤඥඦටඨඩඪණඬතථදධනඳපඵබභමඹයරලවශෂසහළෆ්ාැෑිීුූෘෙේෛොෝෞෟ෴กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลฦวศษสหฬอฮฯะัาำิีึืฺุูเแโใไๅๆ็่้๊๋์ํ๎๏๛ກຂຄງຈຊຍດຕຖທນບປຜຝພຟມຢຣລວສຫອຮະັາຳິີຶືຸູົຼຽເແໂໃໄໆ່້໊໋໌ໍໜໝༀ༆༈་༌།༎༏༑༔༵༼༽ཀཁགངཅཆཇཉཊཋཌཎཏཐདནཔཕབམཙཚཛཝཞཟའཡརལཤཥསཧཨཪཬཱིེཻོཽུཾཿ྄ྀྂྃྈྋྐྒྔྕྗྙྚྟྡྣྤྦྨྩྫྭྰྱྲླྵྶྷ࿆ကခဂဃငစဆဇဈဉညဋဌဍဎဏတထဒဓနပဖဗဘမယရလဝသဟဠအဢဣဤဥဦဧဨဩဪါာိီုူေဲဳဴဵံ့း္်ျြွှဿ၊။၌၍၎၏ၐၑၒၓၔၕၗၚၛၜၝၞၠၡၢၣၤၥၦၧၨၪၫၬၭၰၱၲၳၵၶၷၸၹၺၻၼၽၾၿႀႁႂႃႄႅႆႇႈႉႊႋႌႍႎႏႚႜႝႠႢႣႨႩႫႬႮႰႵႶႷႿჁაბგდევზთიკლმნოპჟრსტუფქღყშჩცძწჭხჯჰჱჲჳჴჵჶჷჹჺᄀᄅᄽᅮᆞሀሁሂሃሄህሆሇለሉሊላሌልሎሏሐሑሒሓሔሕሖሗመሙሚማሜምሞሟሠሡሢሣሤሥሦሧረሩሪራሬርሮሯሰሱሲሳሴስሶሷሸሹሺሻሼሽሾሿቀቁቂቃቄቅቆቇቈቋቌቐቑቒቓቕቖቚቛቜበቡቢባቤብቦቧቨቩቪቫቬቭቮቯተቱቲታቴትቶቷቸቹቺቻቼችቾቿኀኁኂኃኄኅኆኈኊኋኌኍነኑኒናኔንኖኗኘኙኚኛኜኝኞኟአኡኢኣኤእኦኧከኩኪካኬክኮኯኰኲኳኴኵኸኹኺኻኼኽኾዂዃዄወዉዊዋዌውዎዏዐዑዒዓዔዕዖዘዙዚዛዜዝዞዟዠዡዢዣዤዥዦየዩዪያዬይዮዯደዱዲዳዴድዶዷዸዹዺዻዼዽዾጀጁጂጃጄጅጆጇገጉጊጋጌግጎጏጐጒጓጔጕጘጙጚጛጝጟጠጡጢጣጤጥጦጧጨጩጪጫጬጭጮጯጰጱጲጳጴጵጶጷጸጹጺጻጼጽጾፀፁፂፃፄፅፆፇፈፉፊፋፌፍፎፏፐፑፒፓፔፕፖፗፙፚ፝፟፠፡።፣፤፦ᎀᎁᎂᎃᎄᎅᎆᎇᎋᎠᎡᎢᎣᎤᎥᎦᎧᎨᎩᎪᎫᎬᎭᎮᎯᎰᎱᎲᎳᎴᎵᎶᎷᎸᎹᎻᎽᎾᎿᏀᏁᏂᏃᏄᏅᏆᏇᏉᏊᏋᏌᏍᏎᏐᏑᏒᏓᏔᏕᏖᏗᏘᏙᏚᏛᏜᏝᏞᏟᏠᏡᏢᏣᏤᏥᏦᏧᏨᏩᏪᏫᏬᏮᏯᏰᏱᏲᏳᏴᏸᏹᏺᏻᏼᐁᐃᐄᐅᐊᐎᐏᐑᐒᐘᐜᐝᐟᐢᐤᐦᐧᐨᐪᐯᐳᐴᐶᐸᐺᐻᑂᑆᑉᑊᑋᑌᑎᑐᑑᑕᑖᑘᑛᑜᑢᑣᑤᑦᑧᑨᑪᑫᑬᑭᑮᑯᑲᑳᑶᑷᑸᑹᑾᑿᒀᒁᒂᒃᒄᒆᒉᒋᒌᒍᒎᒏᒐᒑᒘᒙᒚᒛᒜᒝᒣᒤᒥᒦᒧᒪᒫᒶᒷᒸᒹᒺᒼᓂᓃᓄᓅᓇᓈᓋᓌᓍᓎᓏᓐᓕᓗᓚᓦᓧᓪᓫᓬᓮᓯᓰᓱᓲᓴᓵᓺᓾᓿᔅᔆᔐᔑᔓᔕᔖᔙᔚᔛᔜᔡᔢᔣᔤᔥᔩᔪᔫᔭᔮᔷᔼᔿᕆᕈᕉᕊᕋᕍᕐᕒᕓᕗᕘᕙᕚᕞᕠᕢᕦᕧᕨᕩᕫᕬᕮᕯᕰᕱᕲᕳᕴᕵᕶᕼᕾᕿᖀᖅᖆᖇᖏᖑᖒᖓᖔᖘᖙᖠᖫᖯᖰᖱᖲᖳᖴᖶᖸᖺᖻᖼᖽᖾᖿᗁᗂᗅᗋᗐᗔᗗᗚᗛᗜᗝᗞᗟᗠᗡᗢᗥᗦᗨᗩᗪᗫᗬᗭᗯᗰᗱᗲᗳᗴᗵᗷᗸᗹᗼᗽᗾᗿᘂᘉᘍᘎᘏᘐᘑᘒᘓᘔᘗᘘᘙᘜᘝᘢᘮᘳᘴᘹᘺᘻᘿᙀᙁᙅᙈᙊᙍᙎᙏᙐᙑᙒᙓᙔᙖᙗᙘᙙᙛᙜᙝᙞᙟᙡᙢᙣᙤᙥᙦᙧᙪᙫᙬ᙭ᚊᚠᚡᚢᚣᚤᚦᚨᚩᚪᚫᚬᚮᚱᚲᚳᚴᚵᚷᚹᚺᚻᚼᚾᚿᛁᛂᛃᛄᛆᛇᛈᛉᛊᛋᛍᛏᛐᛑᛒᛖᛗᛘᛚᛝᛞᛟᛣ᛫ᜀᜁᜂᜃᜄᜅᜆᜇᜈᜉᜊᜋᜌᜎᜏᜐᜑᜒᜓ᜔កខគឃងចឆជឈញដឋឌឍណតថទធនបផពភមយរលវឝឞសហឡអឣឥឦឧឨឩឪឫឬឭឮឯឰឱឲឳ឴ាិីឹឺុូួើឿៀេែៃោៅំះៈ៉៊់៌៍៎៏័៑្៓។៖ៗ៚᠌ᠠᠡᠢᠣᠤᠥᠦᠧᠨᠩᠪᠫᠬᠭᠮᠯᠰᠱᠲᠳᠴᠵᠶᠷᠸᠾᡃᡄᡅᡇᡉᡑᡕᡠᡤᡨᡩᡳᡵᢆᢚᢤᢨᣃᣄᤀᤁᤂᤃᤅᤆᤇᤈᤋᤌᤍᤎᤏᤐᤑᤒᤓᤔᤕᤖᤗᤘᤙᤛᤜᤠᤡᤢᤣᤥᤧᤩᤪᤰᤱᤴᤶᤷ᤻᥄ᥐᥑᥓᥔᥕᥖᥗᥙᥛᥜᥝᥞᥠᥡᥢᥣᥦᥨᥩᥪᥫᥭᥰᥱᥲᥴᦏᦒᨀᨂᨄᨅᨆᨈᨉᨊᨍᨏᨑᨒᨓᨔᨕᨖᨗᨙᨚᩎᬡᬥᬦᬧᬬᬯᬾ᭄ᮁᮂᮃᮄᮅᮌᮒᮓᮔᮕᮖᮙᮛᮜᮝᮞᮟᮤᮥᮨ᮪ᮼᮽᯇᯤᯩᯱᰄᰭᰯᰱᱚᱛᱜᱝᱞᱟᱠᱡᱢᱣᱤᱥᱦᱧᱨᱩᱫᱬᱭᱮᱯᱰᱱᱲᱳᱴᱵᱶᱷᱸᱹᱽᴀᴄᴅᴆᴇᴉᴊᴋᴍᴏᴑᴓᴖᴗᴘᴙᴚᴛᴜᴟᴠᴢᴥᴧᴨᴫᴬᴮᴰᴱᴲᴳᴴᴵᴶᴷᴸᴺᴻᴼᴽᴿᵀᵁᵅᵇᵏᵐᵔᵜᵞᵡᵩᵪᵯᵴᵵᵸᶒᶓᶔᶕᶜᶠᶢᶤᶨᶯᶰᶸᶻ᷊᷽᷿᷈᷉᷋ᷝᷞᷟᷧ᷾᷍ḀḁḂḃḄḅḆḇḈḉḊḋḌḍḎḏḐḑḒḓḔḕḖḗḘḙḚḛḜḝḞḟḠḡḢḣḤḥḦḧḨḩḪḫḬḭḮḯḰḱḲḳḴḵḶḷḸḹḺḻḼḽḾḿṀṁṂṃṄṅṆṇṈṉṊṋṌṍṎṏṐṑṒṓṔṕṖṗṘṙṚṛṜṝṞṟṠṡṢṣṤṥṦṧṨṩṪṫṬṭṮṯṰṱṲṳṴṵṶṷṸṹṺṻṼṽṾṿẀẁẂẃẄẅẆẇẈẉẊẋẌẍẎẏẐẑẒẓẔẕẖẗẘẙẚẛẜẝẞẟẠạẢảẤấẦầẨẩẪẫẬậẮắẰằẲẳẴẵẶặẸẹẺẻẼẽẾếỀềỂểỄễỆệỈỉỊịỌọỎỏỐốỒồỔổỖỗỘộỚớỜờỞởỠỡỢợỤụỦủỨứỪừỬửỮữỰựỲỳỴỵỶỷỸỹỺỻỼỽỾỿἀἁἂἃἄἅἆἇἈἉἌἍἏἐἑἒἓἔἕἘἙἛἜἝἠἣἤἥἧἨἩἪἬἭἯἰἱἲἳἴἵἶἸἹἼὀὁὂὃὄὈὉὋὐὓὔὕὖὗὙὛὝὠὣὦὧὮὯὰὴήὶὸὺὼᾀᾂᾃᾄᾆᾇᾊᾋᾌᾏᾐᾑᾕᾖᾗᾘᾝᾟᾤᾥᾬᾰᾱᾴᾶᾷᾸΆῂῆῊῐῑῒῖῡῢῥῦῨῬῳῴῶῷῺ–—‗‘’‚“”„†‡•…‧‰‹›※‼⁂ⁱ₎ₓ₥€₯⃒⃘⃚⃔⃕⃖⃗⃜⃝⃞⃟⃠⃡⃢⃣⃤⃦⃫⃬⃭⃮⃯⃧⃩ℂ℅ℇℑℒℓℛ℠™ΩℬℯℱℴⅅⅡⅢⅴ↯∂∑∞∩∫≈≠≡≤≥≦≧⊕⊰⊱⋁⋆⋋⋌⌣⎛⎝⎞⎠⎲⎵⎷⏎⏝⏠⑩⑫⑰ⒶⒷⒸⒺⒻⒿⓀⓂⓄⓊⓋⓌⓏⓐⓓⓖⓚⓛⓝⓟⓦⓨ⓫─━│┌┐└┘├┤┼═║╔╗╘╚╛╝╣╤╦╧╩╪╬╭╮╯╰▁▂▃▅▆▇█░▒▓▷►▼◁◄◇◊◒◔◘◡◢◤◪☀★☆☊☜☡☥☭☮☺☼☾♈♔♛♡♣♪✂✅✇✌✎✓✔✗✘✝✞✟✣✤✥✦✩✪✫✬✭✮✯✰✱✲✹✿❀❁❂❃❄❉❊❣❤❥❦❧❿➜➸⠀⣧ⱢⱤⱥⱦⱭⱮⱯⱾⱿⴇⴈⴌⴟⴰⴱⴲⴳⴴⴵⴶⴷⴸⴹⴺⴻⴼⴽⴾⴿⵀⵁⵂⵃⵄⵅⵆⵇⵈⵉⵊⵋⵍⵎⵏⵐⵒⵓⵔⵕⵖⵗⵘⵙⵚⵛⵜⵝⵞⵟⵠⵡⵢⵣⵤⵥⵧⵯⷡⷥⷦⷪⷭⷮⷯⷴ⺌、。々〆〈〉《》「」『』【】〘〙〜〤ぁあぃいぅうぇえぉおかがきぎくぐけげこごさざしじすずせぜそぞただちぢっつづてでとどなにぬねのはばぱひびぴふぶぷへべぺほぼぽまみむめもゃやゅゆょよらりるれろゎわゐゑをんゔゖゝゞァアィイゥウェエォオカガキギクグケゲコゴサザシジスズセゼソゾタダチヂッツヅテデトドナニヌネノハバパヒビピフブプヘベペホボポマミムメモャヤュユョヨラリルレロヮワヰヱヲンヴヵヶヷ・ーヽヾㄊㄎㄓㄝㄞㄨㄱㄴㄹㅁㅇㅈㅉㅍㅎㅐㅓㅔㅖㅗㅜㅡㅣㅤㆍ㊖㊣㋖㋛㋡㔶㕥㛄㣄㩧㩮㮈㺩䉀䑂䑓䕃䭓一丁丂七丅万丈三上下不与丑丒专且丕世丘丙业丛东丝丞丟両两严並丨个丫中丰串临丶丷丸丹为主丼丽丿乀乂乃乄久乇么义之乌乍乎乐乒乓乔乖乗乘乙乛乜九也习乡书买乱乳乾亀亂了予争事二于亐云互亓五井亖亗亘亙亚些亜亞亟亠亡亢交亥亦产亨亩享京亭亮亰亲亵亷人亻亼亽亾亿什仁仅仇仈今介仌仍从仏仓仔仕付仙仚仝仟代令以仨仪们仮仰仲件价仺任份企伈伉伊伍伏休众优伙会伝伞伟传伤伦伯伱伴伶伸伺似伽但位低住佐佑体何佖佘余佛作你佣佩佬佰佳佶使侃來例侍侏侑侖供依侞侠価侣侥侧侨侯侶便係促俄俊俐俗俙俚保俞俠信俣俪俬俭修俯俵俺俽倉個倍倒倖候倚借倡値倦倩倪倫倭倸倻值倾假偈偉偌偏做停健偩偲偳側偵偶偷偽傀傅傍傑傘備傢催傭傲傳債傷傻傾働像僑僕僖僚僡僮僰僱僵價僾儀億儉儍儒償儡優儷儸儿允元兄充兆先光克免兎児兒兔党兜入內全兩八公六兮兰共兲关兴兵其具典兹养兼兽冀冄内円冇冈冉冊冋册再冒冖写军农冠冢冥冧冨冬冭冯冰冲决冴冶冷冻冼冽净凄准凉凊凌凍减凘凛凜凝凞几凡凤処凪凯凰凱凳凸出击函刀刁刃刄分切刈刊刑划列刘则刚创初删判別利刪别刮到制券刹刺刻剀則削剌前剎剑剔剛剡剣剤副剱割剴創劇劉劍劏劑力办功加务劣动助努劫劬劭励劲劳効劼势勁勃勅勇勉勋勍勒動勘務勛勝勞募勢勤勲勳勵勻勿匀匂包匒匕化北匙匚匠匡匪匯匱匹区医匿區十千卄升午卉半卌华协卑卓協单卖南単博卜卝卞占卡卢卣卦卧卫卯印危即卵卷卽卿厂厄历厌厘厚原厠厤厦厨厭厲厳厶厷去叁参參叄又叉及友双反収发叔取受变叙叛叡口古句另只叫召叭叮可台史右叶号司叻叼吃各吇合吉吋同名后吏吐向吕吗君吟吡吥否吧含听吮启吱吳吴吵吸吹吻吼吾呀呂呆呇呈呉告呐呑呒呓呖呗员呢呦周呪呱味呵呼命咀咁咂咄咋和咏咐咔咕咖咘咚咣咩咪咯咲咳咽咿哀品哆哇哈哉哋响哎哒哓哔哟員哥哩哪哭哮哲唄唆唇唉唏唐唔唖唜唧售唯唱唲唹啄商啊問啓啟啡啤啦啵啸啼啾喀喃善喆喇喉喊喔喘喜喝喪喬單喰喱喵営喷喻嗎嗏嗖嗚嗜嗣嗦嗪嗫嗯嗱嘉嘎嘘嘚嘛嘜嘟嘠嘩嘭嘯嘲嘻嘿噌噗噛噜噠噢器噴噶噹嚇嚐嚕嚧嚮嚴嚼囉囊囍囗囚四囝回囟因囡团団囧园囯困図囹固国图圃圆圈國圍園圓圖團土圣圧在圭地圳场址坂均坊坎坏坐坑块坙坚坛坝坡坤坦坪坭坷垂型垚垠垢垣垫垲埃城埔埜域埴執培基埼堀堂堃堅堇堊堕堡堤堪堯堰報場堵堺塁塊塋塑塔塗塘塙塚塞塩填塱塲塵境墅墊墓増墙增墨墮墳墾壁壇壊壕壘壞壤士壮壯声壱売壳壶壷壹壺壽处备変夊夌复夏夕外夘多夛夜够夠夢大天太夫夬央夯失头夷夺奀奄奇奈奉奋奎奏奐契奔奕奖套奠奢奥奧奨奪奮女奴奵奶奸好如妃妄妆妇妍妏妒妖妗妘妙妝妤妥妨妩妮妳妹妺妻姆姉始姍姐姑姓委姗姚姜姝姨姫姬姲姳姵姶姷姸姿威娃娅娇娉娒娘娛娜娟娣娥娫娳娴婀婆婉婕婗婚婞婦婧婭婳婴婵婷媁媂媒媖媚媛媜媽嫁嫂嫌嫒嫙嫚嫣嫦嫩嫲嫻嬅嬉嬊嬋嬌嬡嬣嬤嬪嬰嬷嬸嬿孃孋子孑孔孖字存孙孛孜孝孟季孤学孩孫孬孱學孽宁它宅宇守安宋完宍宏宓宗官宙定宛宜宝实実客宣室宥宧宪宫宬宮宰宲宵家宸容宽宾宿寁寂寄寅密寇富寐寒寓寘寛寝寞察寡實寧審寫寬寮寯寰寳寵寶寸对寺寻导対寿封専射将將專尉尊尋對導小尐少尒尔尕尖尘尚尛尤尧尭就尸尹尺尻尼尽尾局屁层居屈届屋屍屏屐屑展屝属屠層屬屯山屺岁岄岐岑岚岛岡岩岫岬岭岱岳岸峇峠峡峤峥峨峪峭峮峯峰島峻崇崊崋崎崑崔崖崚崤崩崴崵嵋嵐嵘嵛嵜嵩嵬嵯嵻嶋嶌嶺嶼嶽巍巒巖巛川州巠巡巢巣工左巧巨巫差己已巳巴巷巻巾币市布帅帆师希帏帕帖帘帝帥带師席帮帯帰帳帶帷常帼帽幅幌幕幟幡幣幫干平年并幸幹幻幼幽幾广広庄庆床序库应底店庙庚府庞庠度座庫庭庵康庸廁廂廄廉廊廖廚廟廠廢廣廳廴延廷廸建廻廾廿开弁异弄弋弍弎式弐弑弒弓弔引弗弘弛弟张弥弦弩弯弱張強弸弹强弼弾彈彌彎彑归当录彗彡形彣彤彥彦彧彩彪彫彬彭彰影役彻彼彾往征径待很律後徐徑徒従得徙從御徦復循微徯徳徴徵德徹徽心忄必忆忌忍志忘忙忞忠忧快忱忲念忸忻忽怀态怎怒怖怜思怠怡急性怨怩怪怷怺总怿恆恋恐恒恕恛恢恥恨恩恬恭息恰恵恺悅悉悌悔悖悟悠悤悦悩悪悬悲悳悴悶情惇惊惑惘惜惟惠惡惣惪惯惰想惹惺愁愈愉意愚愛感愫愷愼愿慈慊態慌慎慕慘慜慢慣慧慨慮慰慶慷憂憎憐憔憤憧憫憬憲憶憾懂應懋懌懐懒懓懦懶懷懸懿戀戅戇戈戎戏成我戒或战戛戦戮戯戰戲戴戶户戸房所扁扆扇手才扎扑扒打托扛扣执扩扬扭扯扳扶批找承技抄把抒抓投抖抗折抚択抢护报抱抵抹押抽担拆拈拉拍拎拒拓拔招拜拝拡拥拨择括拯拱拳拼拽拾拿持指按挑挙挨挪振挺挽挾捌捏换捨据捲捷捺掃掄授掌排掘掛掞掠採探掣接控推措掬揁揉描提揖揚換握揪揮援揼損搜搬搭搵搶携摂摄摆摘摟摩摳摸摺撃撈撒撓撞撤撫播撮撲撳撼擁擂擇擊擋操擔擦擴擺攝攪支攵收攸改攻放政故效敉敌敏救敗教敢散敦敬数整敵敷數文斈斉斋斌斎斐斑斗料斜斡斤斧斩斬断斯新斳斷方於施斿旅旆旋旌旎族旖旗无既旤日旦旧旨早旬旭旱时旷旺旻旼昀昂昆昇昉昊昌明昏易昕昜星映春昧昨昭是昰昱昴昼显時晃晉晋晏晓晖晗晚晞晟晤晧晨普景晰晴晶智暁暄暇暈暉暐暑暖暗暘暢暧暫暮暴暹曄曇曈曉曓曖曙曜曦曰曲曳更曵書曹曺曻曼曽曾替最會月有朋服朔朕朗望朝期朣朧木朩未末本札术朱朴朵机朽杂权杆杉李杏材村杖杜杞束条杢杣来杨杭杯杰東杵杺松板极枋枏析枒林枘枚果枝枠枡枦枫枭枯枰架柁柃柄柊柏某柑柒染柔柘柚柜柞柠查柯柱柳柴柵査柾柿栁栂栃栄标栈栋栎树栓栖栗栝栞校栢栤栩栵样核根格栽桀桁桂桃案桉桊桌桐桑桒桓桔桜桝桟桢档桥桦桧桩桶梁梅梓梘梛條梟梠梢梦梧梨梭梯械梵梶梿棄棉棋棒棕棗棘棚棟棠棧森棱棻棿椀椅椋植椎椒椙椛検椰椽椿楊楒楓楚楜楠楡楢楧楨業楯楳極楷楸楹楼楽概榆榈榊榎榑榕榛榜榟榮榴榺槀槁槇構槌様槙槺槻槽樂樊樋樑樓樗標模樣権横樫樱樹樺樽橄橋橘橙橞機橡橫檀檎檔檜檩檪檬檳檸櫛櫟櫥櫲櫻欄欅權欖欠次欢欣欧欲欸欺欽款歆歌歐歡止正此步武歩歪歯歳歴歷歸死殇殉殊残殘殡殤殭殯殴段殷殺殻殼殿毅毉母毎每毓比毘毛毫毬氏民氓气氕気氛氢氣水氵氷永氹汀汁求汉汎汐汓汕汗汚汝江池污汤汪汰汲汶決汽汾沁沂沃沄沅沈沉沐沒沓沖沙沚沛没沢沧沪沫沬沭河沵沸油沺治沼況泉泊泋泓法泗泞泠泡波泣泥注泪泫泯泰泳泵泼泽洁洋洒洗洙洛洞津洧洨洪洫洮洱洲洵洸洹洺活洽派流浄浅浈测济浓浚浜浠浣浦浩浪浬浮浴海浸涁涂涅消涌涓涔涙涛涞涠润涩涯液涳涵涼淀淂淇淋淑淓淖淘淙淚淞淡淣淨淩淪淮淯深淳淵淸淺添淼渃清済渉渊渋渓渕渚渝渠渡渣渥渦温測渭港渴游渺渼渾湄湊湋湏湖湘湚湛湧湫湬湮湯湾湿満溈源準溜溝溟溢溥溦溧溪溫溯溱溶滄滇滉滋滐滑滔滕滙滝满滢滨滩滴滸滿漁漂漆漉漎漏漓演漠漢漣漩漪漫漬漸漾漿潇潋潑潓潔潘潛潜潟潤潭潮潺潼潾澁澄澌澍澎澐澔澜澡澤澧澪澰澱澳澹激濃濑濕濟濠濡濤濫濬濮濰濱濵濺瀅瀏瀚瀛瀟瀧瀨瀬瀾灌灏灑灘灜灝灣火灬灯灰灵灸灼災灿炉炎炒炖炙炜炫炭炮炳炸点為炼炽烂烈烏烘烛烝烟烤烦烨热烹烽焉焊焕焗焙焚焜無焦焯焰焱然焻焼煇煉煊煌煒煕煙煜煞煥煦照煩煬煮煱煵熄熈熊熔熙熟熠熨熭熱熹熽熾燁燃燄燈燊燎燐燒燕燚營燦燭燾燿爆爐爛爧爪爭爰爱爵父爷爸爹爺爻爽爾爿牆片版牌牙牛牟牡牧物牵特牽犀犬状犽狀狂狄狐狗狙狛狡狩独狭狮狱狸狼猎猛猜猟猡猥猩猪猫猬献猴猶猷猿獄獅獎獠獣獧獨獲獵獸獻玄率玉王玎玖玗玛玟玡玢玥玦玨玩玫玮环现玲玹玺玻珀珂珅珈珉珊珍珏珑珞珠珣珩班珮珳珺珽現琁球理琇琉琛琝琡琢琤琥琦琨琪琬琮琰琲琳琴琵琼琿瑀瑂瑄瑋瑚瑛瑜瑞瑟瑠瑤瑩瑪瑰瑱瑳瑶瑾璀璁璃璇璋璐璓璘璟璢璣璧璨環璸璽瓅瓊瓏瓔瓜瓢瓦瓶瓷甄甌甕甘甚甜生產産用甩甫田由甲申甴电男甸町画畈界畑畔留畝畠畢略畦番畫畯異畱畳當畹疇疋疍疏疑疗疫疯疲疼疾痔痕痛痞痧痴痹痺瘋瘦療癒癡癫癲癸発登發白百的皆皇皎皐皓皕皛皮皿盃盅盆盈益盎盏盐监盒盖盗盘盛盜盟盠盡監盤盧目盯盲直相盼盾省眉看県眞真眠眷眼眾着睛睜睡督睦睪睫睿瞎瞥瞬瞭瞳瞿矚矜矢知矩矫短矮石矶矿码砂研砕砥砰破砵砸硕硝硬确硲硴碌碍碎碑碓碕碗碧碩碹確碼磁磊磐磗磚磡磧磨磯礁礒示礼社祁祇祈祉祐祖祚祛祜祝神祟祢祤祥票祭祯祷祺祿禁禄禅禎福禤禧禪禮禰禹禺离禾禿秀私秉秋种科秒秘秝租秣秤秦积称移稀程税稔稗稙稚稜種稱稲稻稼稽稿穀穂穅穆積穎穏穐穗穣穩穴究穹空穿突窈窗窝窩窪窯竅竈立站竜竞竟章竣童端競竹竺笅笆笑笔笘笙笛笠符笨第笳笹筆筈等筋筍筑筒答策筛筝筠筩筬筱筵筽简箆箇箏箕箖算箜管箭箱箸節範篇築篝篠篤篥篭簑簗簡簾簿籃籌籍籏籐籔籟籠籣籬籲米籽籾粉粋粒粕粗粘粛粟粥粦粧粮粱粵粹精糀糊糕糖糟糠糧糯糸系紀約紅紋納紐紓純紗紘紙級紛素紡索紧紫累細紳紶紸紹紺終絃組絆絋経結絕絛絜絡絢給絮統絲絳絵絶絹綉經綕継続綜綠綢綣綨綪維綱網綴綵綸綺綽綾綿緊緋総緑緒線緣編緩緯緲練緹緻縁縄縈縓縛縢縣縫縱縹總繁繃繆織繡繣繩繪繭繽繾纈續纐纖纞红纤约级纪纬纭纯纱纲纳纵纶纷纸纹纽纾线练组绅细织终绍经绒结绘给绚络绝统绣绥继绩绪绫续绮绯维绵综绿缇缈缋缌缐缓缔缘缤缥缶缺罅罐罒罓罕罗罚罡罢罪置罰罵罷羀羅羈羊美羚羡羢群羨義羲羽羿翁翅翊翌翎習翔翘翟翠翡翩翫翰翱翲翹翻翼翾耀老考者耆而耐耕耗耘耜耨耳耶耽耿聂聆聊联聖聘聚聞聡聪聯聰聲聶職聽聾聿肁肃肆肇肉肌肖肘肚肛肝肠股肤肥肩肪肯育胃胆背胎胖胜胞胡胤胥胭胶胸能脂脅脆脇脈脉脑脖脚脩脸脹脾腊腕腥腦腩腮腰腱腸腹腾腿膀膏膓膚膜膝膠膳膽臂臉臖臣臥臧臨自臭至致臺臻臼舅與興舊舌舍舎舒舖舘舛舜舞舟舩航般舶船艇艚艦良色艳艶艷艸艹艺艾节芃芊芋芑芒芓芙芝芠芣芥芦芩芫芬芭芮芯花芳芴芷芸芹芽苅苇苍苏苑苓苕苗苛苟苠苡若苦苧苫苯英苹苺苾茁茂范茄茅茉茔茗茛茜茤茨茫茱茲茳茴茵茶茸茹荃荆草荊荍荏荒荔荘荟荡荣荭荳荷荻荼莉莊莎莓莘莙莛莜莣莨莪莫莱莲莳获莹莼菀菁菅菇菈菊菌菏菓菖菜菞菟菠菡菩華菰菱菲菸菻菽菿萄萊萌萍萓萝萠萢萤营萧萨萩萬萱落葆葉葑著葛葡董葦葫葬葭葱葳葵葶葺蒂蒋蒔蒙蒜蒞蒣蒨蒲蒸蒹蒻蒼蒽蓁蓉蓋蓏蓑蓓蓙蓜蓝蓥蓬蓮蓼蔆蔓蔗蔚蔟蔡蔣蔥蔦蔧蔭蔵蔺蔻蔼蕃蕉蕊蕎蕗蕙蕨蕫蕭蕲蕴蕷蕾薄薆薇薈薏薑薔薗薙薛薜薡薦薩薪薫薬薮薯薰藁藃藍藏藕藝藤藥藩藪藰藻蘆蘇蘊蘋蘏蘑蘓蘔蘭蘾蘿虄虎虐虑虔處虚虛虞號虫虹虾蚁蚂蚊蚪蚵蛇蛋蛍蛙蛟蛤蛭蛮蛯蜀蜂蜃蜊蜓蜚蜜蜡蜢蜥蜷蜻蝀蝃蝉蝌蝎蝙蝟蝠蝦蝪蝴蝶蝸螂螃融螞螢螺蟆蟑蟲蟷蟹蟻蠍蠔蠟蠡蠢蠻血衅衆行衍術街衛衝衞衡衣补表衫衬衮衰衿袁袆袈袋袓袖被袴裁裂裃装裏裔裕補裝裟裡裬裳裴裹製裾複褌褏褓褚褲襟襪襲西覀要覃覅覇見規視覚覧親観覺觀见观规觅视览觉角觜解触言訂計訊討訓託記訩訪設許訴訶証詐詔評詞詠詡試詩詮詰話詳詹詺誅誇誉誌認誒誓誘語誠說説読誰課誼調諄談請諌諏諒論諠諦諫諭諮諱諵諸諺諾謀謂謄謎謙謚講謝謴謹證識譙譚譜警議譲護譽譿讀讃變讐讓讚计订讨让训讯记讲讷许论访诀证评识诉诊诏译诒试诗诚话该详语诱说诶请诸诺读调谆谈谊谎谐谙谢谦谨谭谷豆豈豉豊豎豐豔豕豚象豪豫豬豭豹豺貅貓貔貝貞負財貢貧販貫貮貳貴買貸費貽貿賀賃資賈賊賓賛賜賞賠賢賣賦質賴購賽贀贄贈贝贞贡财贤账购贰贱贵贸费贺贻贼贾资赈赋赐赓赖赛赞赢赤赦赫走赳赴赵起超越趙趣足趴跃跋跌跑距跟跡跨跩路跳踏踞踩踪蹈蹟蹤蹦躅躍躑身躺車軌軍軒軟転軸軻軽較載輊輔輕輝輩輪輸輿轅轉轎轟车轨轩转轮软轶轻辅辈辉输辕辛辜辞辣辭辰農边辺辻込达辿迁迅过迈迎运近返还进远违连迟迦迩迪迫迭述迴迷迹迺追退送适逃逅逆选逊逍透逐逑途逖逗這通逝速造逢連週進逸逺逼逽遂遄遅遇遊運過遐道達違遗遙遜遞遠遢遣遥適遲遴選遺遼避邁邂還邉邊邋邏邑邓邝邢那邦邨邪邬邱邵邹邻郁郎郑郝郞郡部郭郵郷郺都郿鄉鄒鄔鄞鄥鄧鄭鄺酃酉酊酋配酒酔酢酥酩酬酵酷酸醉醋醍醐醒醜醫醬醸醺釆采釈釉释釋里重野量金釘釜針釡釣釧釨釼鈍鈐鈑鈕鈞鈣鈦鈮鈴鈺鈿鉃鉄鉅鉈鉛鉢鉱鉾銀銅銑銓銕銘銜銭銮銳鋆鋐鋒鋤鋪鋭鋰鋳鋼錄錋錐錒錕錚錠錡錢錦錫錬錯録錶鍆鍇鍊鍋鍛鍜鍬鍵鍶鍾鎂鎇鎊鎌鎔鎖鎛鎧鎬鎮鏆鏈鏋鏑鏗鏞鏟鏡鏵鏻鐘鐙鐵鑒鑓鑣鑫鑽针钊钕钚钜钟钡钢钥钦钧钮钰钱钲钶钸钻铁铃铎铛铠铤铧铨铭铮铵银铺链销锁锅锋锌锎锐锗锝锟锠锣锤锦锫键锲锴锶锺镁镅镇镒镔镖镜镫镭镱長长門閃閉開閑閒間閔閘閙関閣閬閲閻闆闇闊闒闘關门闪闭问闯闲间闷闹闻阀阁阅阌阎阑阗阙阚阜阝队阡阪阮防阳阴阿陀附际陆陈陌降限陞院陣除陨险陪陰陳陵陶陷陸険陽隅隆隈隊隋階随隐隔際隠隣隧隨險隱隳隴隷隹隻隼隽难隿雀雁雄雅集雇雉雋雌雍雏雑雕雙雛雜雞離難雨雪雯雲零雷電雾需霁霂霄霆震霈霉霊霍霏霓霖霜霞霧霭露霸霹靂靄靈靑青靓靖静靚靜非面革靭靳靴鞋鞍鞘鞠鞥韋韓韦韩韫韬韮音韵韶韻響頁頂頃順須頌預頒頓頔頗領頡頤頨頬頭頰頴頹頻頼顆題額顏顓顔顕願顛類顧顯页顶顺顽顾顿颂预领颉颍颐频颖题颜额颠風颯飄飆风飏飕飘飚飛飞食飠飢飯飲飴飼飽飾餃餅養餌餐餒餓餘館饅饒饗饪饭饮饰饺饼首香馜馥馨馬馮馳馴馷駁駄駆駒駕駝駱駿騎騏験騦騫騮騰騷驀驊驕驗驚驛驢马驰驴驷驻驾驿骄骆骏骑骗骨體高髙髪髭髮鬃鬆鬍鬚鬥鬮鬱鬼魁魂魃魄魅魇魈魉魍魏魑魔魚魯魰魷鮎鮑鮒鮨鮪鮫鮮鯉鯊鯛鯨鰂鰐鰻鱗鱻鱼鲁鲍鲜鲨鲸鳞鳥鳩鳯鳲鳳鳴鴇鴉鴨鴩鴫鴻鴾鴿鵜鵝鵤鵬鵲鵽鶏鶑鶴鷄鷇鷗鷲鷹鷺鸞鸟鸡鸢鸣鸥鸦鸭鸽鸾鸿鹂鹅鹌鹏鹑鹤鹰鹽鹿麂麈麒麓麗麟麥麦麵麺麻麼麽麿黃黄黍黎黑黒黔默黙黛點黟黨鼈鼎鼐鼓鼠鼻鼾齊齋齐齡齢齪齮齷龄龍龐龔龘龙龚龜龟ꀀꀆꀇꀈꀊꀋꀎꀒꀓꀘꀡꀤꀧꀪꀭꀷꀸꁅꁊꁌꁏꁕꁣꁧꁱꁲꁴꁻꂅꂑꂖꂚꂠꂦꂵꃅꃆꃔꃩꃲꃼꄙꄞꄟꅏꅐꅤꆂꆨꆰꆹꇃꇎꇖꇩꈚꈛꈤꈵꈼꉄꉓꉣꊐꊛꊼꋊꋒꋖꋪꋫꋬꌃꌅꌗꌚꌦꌩꍈꍌꍏꍛꍟꍩꎇꎭꏂꏄꏈꏝꏤꏹꏿꐈꐞꑀꑘꒌꓐꓑꓒꓓꓔꓕꓖꓗꓘꓙꓚꓛꓝꓞꓟꓠꓡꓢꓣꓤꓥꓦꓧꓨꓩꓪꓫꓬꓭꓮꓯꓰꓱꓲꓳꓴꓵꓶꓷꓸꓹꓽꔀꔁꔅꔉꔊꔋꔔꔖꔘꔚꔜꔝꔞꔠꔡꔪꔬꔭꔮꔰꔷꔹꔺꔻꔽꕂꕔꕕꕗꕘꕤꕥꕬꕭꕯꕷꕹꕺꕻꖀꖍꖒꖘꖛꖜꖞꖧꖯꖲꖴꖵꖸꖹꖻꖼꖽꗃꗄꗈꗋꗍꗛꗜꗝꗞꗟꗣꗥꗮꗯꗰꗴꗶꘂꘈꘌꘐꘑꘒꘖꘘꘜꘝꙨꙮ꙰꙲ꜭꝄꝅꝫꝮꝯꞀꞍꞪꞫꞬꞮꞰꞱꞲꠀꠇꠎꠖꠝꠞꠡꠣꠤꠥꠦꡰꤋꤎꤚꤢꤧꤨ꤬꤭ꤶꦄꦆꦌꦏꦒꦔꦕꦚꦠꦤꦥꦦꦩꦪꦫꦮꦱꦲ꦳ꦴꦶꦸꦺꦿ꧀꧁꧆ꧼꧾꪋꪔꪖꪜꪲꪳꫛꫝ꫞ꫪꭰꭱꭲꭳꭴꭵꭶꭷꭸꭹꭺꭻꭼꭽꭾꭿꮀꮁꮂꮃꮄꮅꮆꮇꮈꮉꮊꮋꮍꮎꮏꮐꮑꮒꮓꮔꮕꮖꮗꮘꮙꮚꮛꮜꮝꮞꮟꮠꮡꮢꮣꮤꮥꮦꮧꮨꮩꮪꮫꮬꮭꮮꮯꮰꮱꮲꮳꮴꮵꮶꮷꮸꮹꮺꮻꮼꮽꮾꮿꯀꯁꯂꯃꯄꯅꯆꯇꯈꯉꯊꯋꯌꯍꯎꯏꯐꯑꯒꯓꯔꯕꯖꯗꯘꯚꯜꯝꯞꯟꯠꯡꯢꯣꯤꯥꯦꯧꯨꯩꯪ꯭가간갈감갑강같개갠갬갯갸거건걸검겉게겐겔겜겠겨격결겸경계고곡곤곰곳공과곽관괂광교구국군굴궁궇권귀규균그극근글금기긴길김깃깊깐깜꺼께껫꼬꼴꽃꾼꿈끄끌나낙난낟날남납낭낳내낸낼냇냉냐냔너넛네넨넬넴넷녀년녈녕노논녿놀놈놋농놏높놓뇌뇨뇸누눈눌느는늘늙늡늬니닉닌닐님닛닜다단닫달담당닽대댁댄댐댜댠더덕덟데덱델뎌도독돈돌돗동될두둔둘둠둥듀듗드득든듣들딈디딕딘딜딧딩딴떠떰떼또똑뚱뜸띠띰라락란랂랄랅람랍랏랑랒랔랗래랜랟랠랫랭랰랴랼럄량러럭런럼렁렂레렉렌렐렘렛렜렣려력련령례로록론롬롯롱롲롸료룡루룩룬룰룽룾뤠류륜률륭르른를름릉릏릐리릭린릳릴림립릿링맂맆마막만많맏말맘맛망맞맠맡맣매맥맨맹맺먀먕머먼먿멋멍멓메멘멜면멶명모목몪몬몯몰몹못몽뫀뫼묘묨묭묲묳무묵묶문묻뭏므믤미믹민믿밀밋밍밑바박반받발밧방밯배백밴밸뱅버번벌범법벗벙벚베벤벨벳변별병보복본봄봅봉봐부북분불붓붕브븍븐블븧비빅빆빈빌빛빨뿌뿐뿔쁘쁜쁨사산살삼샀상샅새색샌샐샘샛생샤샬샴샹서석선설섭섯성세섹센셀셈셉셔셜셰셸소속손솔송솧솨쇼쇽숀숒숓수숙순술숩숭숸쉐슈슐스슥슨슬슴승시식싞신실싫심십싶싸쌍쌰써썬썽쎌쑹쓰씨씬씸씽아악안앉앋알암압앗앙앞앟애액앤앨앰야약얀얌얏얐양얗얘얜얲어언얼엄업없었엉엏에엔엘엠엦엩여역연열영예옏옐오옥온옫올옴옹옿와완왈왑왓왔왕외왼요욕욘욜용우욱운욷울움웃웅워원월웡웨웬위윅윈윌유육윤율으은읃을음응의이익인일읽임입있잉잌자작잔잘잠장재잭잼잿쟁쟆쟈저적전젊점젓정제젠젤젬져조족종좋좌죠주죽준줄중줘쥍쥐쥔쥬즈즌즐증지직진질짐집짖짜짬째쨔쨨쪽쭈쯔찌차착찬찰참창챀채책천철첨청체첸첻첼쳉쳐초촌촞최추축춘출충취츄츠츼치친칠침카칼캉캔캠커컨케켄켈켓켙켜켱켸코콜콤쿳퀴큐큓크큰큺킊키킨킬킴킿타탁탄탈탉탐탕태택탭탱탷터털테텍텐텔템톄토톤톨톰통투툴튜튠튤튬트튼틀티틴팀팃팅파팍판팑팔패팩팬퍼퍽펀펄페펠펴편평폐포폭폴표푸풀품풋풍퓨픀프픈플피필핏핑하학한핟할함합핫항해핸햄햇했행향허헌헐험헤헥헨헬헷혀혁현혈협형혜호혼홀홍화확환활황회횡효횬후훈훌훨휘휴휸흋흐흑흔흟흠흣흥희흱히힌힏힐힘﨑ﬓﬔﬕﬖﬗﬠﬡﬣﬦﬧﬨשּׂאַאָדּהּוּיּלּמּסּצּקּשּתּפֿﭏﭐﭑﭒﭓﭔﭕﭖﭗﭘﭙﭚﭛﭜﭝﭞﭟﭠﭡﭢﭣﭤﭥﭦﭧﭨﭩﭪﭫﭬﭭﭮﭯﭰﭱﭲﭳﭴﭵﭶﭷﭸﭹﭺﭻﭼﭽﭾﭿﮀﮁﮂﮃﮄﮅﮆﮇﮈﮉﮊﮋﮌﮍﮎﮏﮐﮑﮒﮓﮔﮕﮖﮗﮘﮙﮚﮛﮜﮝﮞﮟﮠﮡﮢﮣﮤﮥﮦﮧﮨﮩﮪﮫﮬﮭﮮﮯﮰﮱﯓﯔﯕﯖﯗﯘﯙﯚﯛﯜﯝﯞﯟﯠﯡﯢﯣﯤﯥﯦﯧﯨﯩﯼﯽﯾﯿﰎﰗﰲﱏﱙﱞﱟﱠﱡﱢﱯﲌﲕﲛﲝﲠﲭﳊﳌﳏﳒﳙﳣﳩﳪﳲﳳﳴﳼﴼﴽ﴾﴿ﶊﷲﷳﷴﷶﷸﷺﷻ︎️︶︻ﹰﹱﹲﹳﹴﹶﹷﹸﹹﹺﹻﹼﹽﹾﹿﺀﺁﺂﺃﺄﺅﺆﺇﺈﺉﺊﺋﺌﺍﺎﺏﺐﺑﺒﺓﺔﺕﺖﺗﺘﺙﺚﺛﺜﺝﺞﺟﺠﺡﺢﺣﺤﺥﺦﺧﺨﺩﺪﺫﺬﺭﺮﺯﺰﺱﺲﺳﺴﺵﺶﺷﺸﺹﺺﺻﺼﺽﺾﺿﻀﻁﻂﻃﻄﻅﻆﻇﻈﻉﻊﻋﻌﻍﻎﻏﻐﻑﻒﻓﻔﻕﻖﻗﻘﻙﻚﻛﻜﻝﻞﻟﻠﻡﻢﻣﻤﻥﻦﻧﻨﻩﻪﻫﻬﻭﻮﻯﻰﻱﻲﻳﻴﻵﻶﻷﻸﻹﻺﻻﻼ！（）＊－．ＡＢＣＤＥＦＧＨＩＪＫＬＭＮＯＰＲＳＴＵＷＸＹＺａｂｃｄｅｆｇｈｉｊｋｌｍｎｏｐｑｒｓｔｕｖｗｘｙｚ～｡､ｧｨｰｱｲｴｶｺｻｼｽﾂﾉﾊﾌﾐﾒﾕﾗﾘﾙﾚﾛﾝﾞﾠﾶ�𝓐𝓓𝓗𝓘𝓚𝓛𝓝\n",
      "\n",
      "Number of target classes: 19:\n",
      "Caribbean, Eastern Asia, South-eastern Asia, Western Europe, Eastern Europe, Central Asia, Southern Europe, Melanesia, Northern Europe, Western Asia, Southern Africa, Middle Africa, Western Africa, Central America, Northern America, Northern Africa, Eastern Africa, South America, Southern Asia\n"
     ]
    }
   ],
   "source": [
    "val_data = NameNationalityData(\n",
    "    data_file='./data/val.csv',\n",
    "    maximum_name_length=MAXIMUM_NAME_LENGTH,\n",
    "    vocabulary=VOCABULARY,\n",
    "    country_codes=COUNTRY_CODES,\n",
    "    country_mapping=COUNTRY_MAPPING\n",
    ")\n",
    "val_dataloader = DataLoader(val_data, batch_size=N_EVAL*BATCH_SIZE, drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **MODELING**\n",
    "\n",
    "- Create simple model using character embeddings, rnn layers and a dense layer (todo: dropout, weight initialization)\n",
    "- Find best initial learning rate\n",
    "- Get a baseline crossentropy loss\n",
    "- Get a model to overfit sample data\n",
    "- train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Nationality_Predictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(\n",
    "            num_embeddings=len(VOCABULARY)+1,\n",
    "            embedding_dim=64,\n",
    "            padding_idx=0\n",
    "        )\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=64,\n",
    "            hidden_size=128,\n",
    "            num_layers=3,\n",
    "            batch_first=True,\n",
    "            dropout=0.3\n",
    "        )\n",
    "        self.dense = nn.Linear(\n",
    "            in_features=128,\n",
    "            out_features=len(set(COUNTRY_MAPPING.values()))+1,\n",
    "        )\n",
    "\n",
    "    def forward(self, X, lengths):\n",
    "        embeddings = self.embed(X)\n",
    "\n",
    "        # Pack the padded batch\n",
    "        packed = pack_padded_sequence(\n",
    "            embeddings,\n",
    "            lengths=lengths,\n",
    "            batch_first=True,\n",
    "            enforce_sorted=False\n",
    "        )\n",
    "        _, hidden = self.rnn(packed)\n",
    "        logits = self.dense(hidden[-1])\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN_Nationality_Predictor().to(device)\n",
    "criterion = F.binary_cross_entropy_with_logits\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 100 --- mean training loss over last 100 batches: 0.10037 --- validation loss: 0.10094\n",
      "batch 200 --- mean training loss over last 100 batches: 0.10156 --- validation loss: 0.10027\n",
      "batch 300 --- mean training loss over last 100 batches: 0.09952 --- validation loss: 0.10027\n"
     ]
    }
   ],
   "source": [
    "def train(\n",
    "        n_training_steps: int,\n",
    "        n_eval: int\n",
    "    ) -> None:\n",
    "    batch_number: int = 1\n",
    "    losses: list = []\n",
    "\n",
    "    while True:\n",
    "        for X, y, sequence_lenghts in train_dataloader:\n",
    "            batch_number += 1\n",
    "            model.train()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            logits = model(X, sequence_lenghts)\n",
    "            loss = criterion(logits, y)\n",
    "            losses.append(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                if batch_number%n_eval==0:\n",
    "                    model.eval()\n",
    "                    X, y, sequence_lenghts = next(iter(val_dataloader))\n",
    "                    X, y = X.to(device), y.to(device)\n",
    "                    logits = model(X, sequence_lenghts)\n",
    "                    val_loss = criterion(logits, y)\n",
    "                    print(f'batch {batch_number} --- mean training loss over last {n_eval} batches: {np.mean(losses[-n_eval:]):.5f} --- validation loss: {val_loss:.5f}')\n",
    "            if batch_number >= n_training_steps:\n",
    "                return\n",
    "            \n",
    "train(N_TRAINING_STEPS, N_EVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Northern America']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "tensor, length = train_data._encode_name(['Donald Trump'])\n",
    "tensor = tensor.to(device)\n",
    "logits = model(\n",
    "    tensor,\n",
    "    length\n",
    "    )\n",
    "train_data._decode_country(logits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LearningPyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
